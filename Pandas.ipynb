{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Pandas\n",
    "\n",
    "Pandas is an open-source Python Library providing high-performance data manipulation \n",
    "and analysis tool using its powerful data structures. \n",
    "\n",
    "The name Pandas is derived from the word Panel Data – an Econometrics from Multidimensional data.\n",
    "\n",
    "## Key Features of Pandas\n",
    "- Fast and efficient DataFrame object with default and customized indexing.\n",
    "- Tools for loading data into in-memory data objects from different file formats.\n",
    "- Data alignment and integrated handling of missing data.\n",
    "- Reshaping and pivoting of date sets.\n",
    "- Label-based slicing, indexing and subsetting of large data sets.\n",
    "- Columns from a data structure can be deleted or inserted.\n",
    "- Group by data for aggregation and transformations.\n",
    "- High performance merging and joining of data.\n",
    "- Time Series functionality.\n",
    "\n",
    "## Pandas deals with the following three data structures −\n",
    "- Series\n",
    "- DataFrame\n",
    "- Panel\n",
    "These data structures are built on top of Numpy array, which means they are fast.\n",
    "\n",
    "## Dimension & Description\n",
    "The best way to think of these data structures is that the higher dimensional data structure is a container of its lower dimensional data structure. \n",
    "\n",
    "For example, \n",
    "\n",
    "DataFrame is a container of Series, \n",
    "\n",
    "Panel is a container of DataFrame.\n",
    "\n",
    "|Data| Structure|\tDimensions\tDescription|\n",
    "|-|-|-|\n",
    "|Series|\t1|\t1D labeled homogeneous array, sizeimmutable.|\n",
    "|Data Frames|\t2\t|General 2D labeled, size-mutable tabular structure with potentially heterogeneously typed columns.|\n",
    "|Panel\t|3|\tGeneral 3D labeled, size-mutable array.|\n",
    "\n",
    "Building and handling two or more dimensional arrays is a tedious task, burden is placed on the user to consider the orientation of the data set when writing functions. But using Pandas data structures, the mental effort of the user is reduced.\n",
    "\n",
    "For example, with tabular data (DataFrame) it is more semantically helpful to think of the index (the rows) and the columns rather than axis 0 and axis 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Python Pandas - Series\n",
    "\n",
    "Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.). The axis labels are collectively called index.\n",
    "\n",
    "A pandas Series can be created using the following constructor −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.Series( data, index, dtype, copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# A basic series, which can be created is an Empty Series.\n",
    "#import the pandas library and aliasing as pd\n",
    "import pandas as pd\n",
    "s = pd.Series()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a Series from ndarray\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = np.array(['a','b','c','d'])\n",
    "s = pd.Series(data)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100    a\n",
      "101    b\n",
      "102    c\n",
      "103    d\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# We passed the index values here. Now we can see the customized indexed values in the output.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = np.array(['a','b','c','d'])\n",
    "s = pd.Series(data,index=[100,101,102,103])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0.0\n",
      "b    1.0\n",
      "c    2.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a Series from dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = {'a' : 0., 'b' : 1., 'c' : 2.}\n",
    "s = pd.Series(data)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b    1.0\n",
      "c    2.0\n",
      "d    NaN\n",
      "a    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Passing index\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = {'a' : 0., 'b' : 1., 'c' : 2.}\n",
    "s = pd.Series(data,index=['b','c','d','a'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    5\n",
      "2    5\n",
      "3    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a Series from Scalar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.Series(5, index=[0, 1, 2, 3])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Accessing Data from Series with Position\n",
    "import pandas as pd\n",
    "s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e'])\n",
    "\n",
    "#retrieve the first element\n",
    "print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the first three elements in the Series.\n",
    "import pandas as pd\n",
    "s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e'])\n",
    "\n",
    "#retrieve the first three element\n",
    "print(s[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the last three elements.\n",
    "import pandas as pd\n",
    "s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e'])\n",
    "\n",
    "#retrieve the last three element\n",
    "print(s[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Retrieve Data Using Label (Index)\n",
    "import pandas as pd\n",
    "s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e'])\n",
    "\n",
    "#retrieve a single element\n",
    "print(s['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Retrieve multiple elements using a list of index label values.\n",
    "import pandas as pd\n",
    "s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e'])\n",
    "\n",
    "#retrieve multiple elements\n",
    "print(s[['a','c','d']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a label is not contained, an exception is raised.\n",
    "import pandas as pd\n",
    "s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e'])\n",
    "\n",
    "#retrieve multiple elements\n",
    "print(s['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Python Pandas - DataFrame\n",
    "\n",
    "A Data frame is a two-dimensional data structure, i.e., data is aligned in a tabular fashion in rows and columns.\n",
    "\n",
    "- Features of DataFrame\n",
    "- Potentially columns are of different types\n",
    "- Size – Mutable\n",
    "- Labeled axes (rows and columns)\n",
    "- Can Perform Arithmetic operations on rows and columns\n",
    "\n",
    "A pandas DataFrame can be created using the following constructor −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame( data, index, columns, dtype, copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Create an Empty DataFrame\n",
    "#import the pandas library and aliasing as pd\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from Lists\n",
    "import pandas as pd\n",
    "data = [1,2,3,4,5]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age\n",
      "0    Alex   10\n",
      "1     Bob   12\n",
      "2  Clarke   13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [['Alex',10],['Bob',12],['Clarke',13]]\n",
    "df = pd.DataFrame(data,columns=['Name','Age'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name   Age\n",
      "0    Alex  10.0\n",
      "1     Bob  12.0\n",
      "2  Clarke  13.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [['Alex',10],['Bob',12],['Clarke',13]]\n",
    "df = pd.DataFrame(data,columns=['Name','Age'],dtype=float)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Create a DataFrame from Dict of ndarrays / Lists\n",
    "All the ndarrays must be of same length. If index is passed, then the length of the index should equal to the length of the arrays.\n",
    "\n",
    "If no index is passed, then by default, index will be range(n), where n is the array length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age\n",
      "0    Tom   28\n",
      "1   Jack   34\n",
      "2  Steve   29\n",
      "3  Ricky   42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'Name':['Tom', 'Jack', 'Steve', 'Ricky'],'Age':[28,34,29,42]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name  Age\n",
      "rank1    Tom   28\n",
      "rank2   Jack   34\n",
      "rank3  Steve   29\n",
      "rank4  Ricky   42\n"
     ]
    }
   ],
   "source": [
    "# Let us now create an indexed DataFrame using arrays.\n",
    "import pandas as pd\n",
    "data = {'Name':['Tom', 'Jack', 'Steve', 'Ricky'],'Age':[28,34,29,42]}\n",
    "df = pd.DataFrame(data, index=['rank1','rank2','rank3','rank4'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Create a DataFrame from List of Dicts\n",
    "\n",
    "List of Dictionaries can be passed as input data to create a DataFrame. The dictionary keys are by default taken as column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b     c\n",
      "0  1   2   NaN\n",
      "1  5  10  20.0\n"
     ]
    }
   ],
   "source": [
    "# The following example shows how to create a DataFrame by passing a list of dictionaries.\n",
    "import pandas as pd\n",
    "data = [{'a': 1, 'b': 2},{'a': 5, 'b': 10, 'c': 20}]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Note − Observe, NaN (Not a Number) is appended in missing areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a   b     c\n",
      "first   1   2   NaN\n",
      "second  5  10  20.0\n"
     ]
    }
   ],
   "source": [
    "# The following example shows how to create a DataFrame by passing a list of dictionaries and the row indices.\n",
    "import pandas as pd\n",
    "data = [{'a': 1, 'b': 2},{'a': 5, 'b': 10, 'c': 20}]\n",
    "df = pd.DataFrame(data, index=['first', 'second'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a   b\n",
      "first   1   2\n",
      "second  5  10\n",
      "        a  b1\n",
      "first   1 NaN\n",
      "second  5 NaN\n"
     ]
    }
   ],
   "source": [
    "# The following example shows how to create a DataFrame with a list of dictionaries, row indices, and column indices.\n",
    "import pandas as pd\n",
    "data = [{'a': 1, 'b': 2},{'a': 5, 'b': 10, 'c': 20}]\n",
    "\n",
    "#With two column indices, values same as dictionary keys\n",
    "df1 = pd.DataFrame(data, index=['first', 'second'], columns=['a', 'b'])\n",
    "\n",
    "#With two column indices with one index with other name\n",
    "df2 = pd.DataFrame(data, index=['first', 'second'], columns=['a', 'b1'])\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Create a DataFrame from Dict of Series\n",
    "\n",
    "Dictionary of Series can be passed to form a DataFrame. The resultant index is the union of all the series indexes passed.\n",
    "\n",
    "Note − Observe, for the series one, there is no label ‘d’ passed, but in the result, for the d label, NaN is appended with NaN.\n",
    "\n",
    "Let us now understand column selection, addition, and deletion through examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "a  1.0    1\n",
      "b  2.0    2\n",
      "c  3.0    3\n",
      "d  NaN    4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']),\n",
    "   'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4) Column Selection\n",
    "\n",
    "We will understand this by selecting a column from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1.0\n",
      "b    2.0\n",
      "c    3.0\n",
      "d    NaN\n",
      "Name: one, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']),\n",
    "   'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "print(df['one'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5) Column Addition\n",
    "We will understand this by adding a new column to an existing data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding a new column by passing as Series:\n",
      "   one  two  three\n",
      "a  1.0    1   10.0\n",
      "b  2.0    2   20.0\n",
      "c  3.0    3   30.0\n",
      "d  NaN    4    NaN\n",
      "Adding a new column using the existing columns in DataFrame:\n",
      "   one  two  three  four\n",
      "a  1.0    1   10.0  11.0\n",
      "b  2.0    2   20.0  22.0\n",
      "c  3.0    3   30.0  33.0\n",
      "d  NaN    4    NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']),\n",
    "   'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "# Adding a new column to an existing DataFrame object with column label by passing new series\n",
    "\n",
    "print (\"Adding a new column by passing as Series:\")\n",
    "df['three']=pd.Series([10,20,30],index=['a','b','c'])\n",
    "print(df)\n",
    "\n",
    "print (\"Adding a new column using the existing columns in DataFrame:\")\n",
    "df['four']=df['one']+df['three']\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6) Column Deletion\n",
    "Columns can be deleted or popped; let us take an example to understand how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataframe is:\n",
      "   one  two  three\n",
      "a  1.0    1   10.0\n",
      "b  2.0    2   20.0\n",
      "c  3.0    3   30.0\n",
      "d  NaN    4    NaN\n",
      "Deleting the first column using DEL function:\n",
      "   two  three\n",
      "a    1   10.0\n",
      "b    2   20.0\n",
      "c    3   30.0\n",
      "d    4    NaN\n",
      "Deleting another column using POP function:\n",
      "   three\n",
      "a   10.0\n",
      "b   20.0\n",
      "c   30.0\n",
      "d    NaN\n"
     ]
    }
   ],
   "source": [
    "# Using the previous DataFrame, we will delete a column\n",
    "# using del function\n",
    "import pandas as pd\n",
    "d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), \n",
    "   'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd']), \n",
    "   'three' : pd.Series([10,20,30], index=['a','b','c'])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "print (\"Our dataframe is:\")\n",
    "print(df)\n",
    "\n",
    "# using del function\n",
    "print (\"Deleting the first column using DEL function:\")\n",
    "del df['one']\n",
    "print(df)\n",
    "\n",
    "# using pop function\n",
    "print (\"Deleting another column using POP function:\")\n",
    "df.pop('two')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7) Row Selection, Addition, and Deletion\n",
    "We will now understand row selection, addition and deletion through examples. \n",
    "\n",
    "Let us begin with the concept of selection.\n",
    "\n",
    "### 3.7.1) Selection by Label\n",
    "\n",
    "Rows can be selected by passing row label to a loc function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one    2.0\n",
      "two    2.0\n",
      "Name: b, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), \n",
    "   'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "print(df.loc['b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.2) Selection by integer location\n",
    "Rows can be selected by passing integer location to an iloc function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one    3.0\n",
      "two    3.0\n",
      "Name: c, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']),\n",
    "   'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "print(df.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.3) Slice Rows\n",
    "Multiple rows can be selected using ‘ : ’ operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "c  3.0    3\n",
      "d  NaN    4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), \n",
    "   'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "print(df[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.4) Addition of Rows\n",
    "Add new rows to a DataFrame using the append function. This function will append the rows at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b\n",
      "0  1  2\n",
      "1  3  4\n",
      "0  5  6\n",
      "1  7  8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[1, 2], [3, 4]], columns = ['a','b'])\n",
    "df2 = pd.DataFrame([[5, 6], [7, 8]], columns = ['a','b'])\n",
    "\n",
    "df = df.append(df2)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.5) Deletion of Rows\n",
    "Use index label to delete or drop rows from a DataFrame. If label is duplicated, then multiple rows will be dropped.\n",
    "\n",
    "If you observe, in the above example, the labels are duplicate. Let us drop a label and will see how many rows will get dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b\n",
      "1  3  4\n",
      "1  7  8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[1, 2], [3, 4]], columns = ['a','b'])\n",
    "df2 = pd.DataFrame([[5, 6], [7, 8]], columns = ['a','b'])\n",
    "\n",
    "df = df.append(df2)\n",
    "\n",
    "# Drop rows with label 0\n",
    "df = df.drop(0)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Python Pandas - Xarray\n",
    "-Pandas panel has been removed, explore Xarray later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Python Pandas - Basic Functionality\n",
    "\n",
    "### Series Basic Functionality\n",
    "|Sr.No.|\tAttribute or Method & Description|\n",
    "|-|-|\n",
    "|1|axes<br> Returns a list of the row axis labels|\n",
    "|2|dtype<br> Returns the dtype of the object.|\n",
    "|3|empty<br> Returns True if series is empty.|\n",
    "|4|ndim<br> Returns the number of dimensions of the underlying data, by definition 1.|\n",
    "|5|size<br> Returns the number of elements in the underlying data.|\n",
    "|6|values<br> Returns the Series as ndarray.|\n",
    "|7|head()<br> Returns the first n rows.|\n",
    "|8|tail()<br> Returns the last n rows.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -1.458714\n",
      "1    0.475064\n",
      "2    0.456089\n",
      "3   -0.015047\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Create a series with 100 random numbers\n",
    "s = pd.Series(np.random.randn(4))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The axes are:\n",
      "[RangeIndex(start=0, stop=4, step=1)]\n"
     ]
    }
   ],
   "source": [
    "# axes\n",
    "# Returns the list of the labels of the series.\n",
    "s = pd.Series(np.random.randn(4))\n",
    "print(\"The axes are:\")\n",
    "print(s.axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the Object empty?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# empty\n",
    "# Returns the Boolean value saying whether the Object is empty or not. True indicates that the object is empty.\n",
    "s = pd.Series(np.random.randn(4))\n",
    "print(\"Is the Object empty?\")\n",
    "print(s.empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the object:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# ndim\n",
    "# Returns the number of dimensions of the object. \n",
    "# By definition, a Series is a 1D data structure, so it returns\n",
    "s = pd.Series(np.random.randn(4))\n",
    "print (\"The dimensions of the object:\")\n",
    "print(s.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the object:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# size\n",
    "# Returns the size(length) of the series.\n",
    "s = pd.Series(np.random.randn(2))\n",
    "print(\"The size of the object:\")\n",
    "print(s.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual data series is:\n",
      "[ 2.12879776  1.5501582   0.34871063 -1.58515656]\n"
     ]
    }
   ],
   "source": [
    "# values\n",
    "# Returns the actual data in the series as an array.\n",
    "s = pd.Series(np.random.randn(4))\n",
    "print (\"The actual data series is:\")\n",
    "print(s.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original series is:\n",
      "0   -0.526445\n",
      "1   -0.602228\n",
      "2    0.022171\n",
      "3   -1.246760\n",
      "dtype: float64\n",
      "The first two rows of the data series:\n",
      "0   -0.526445\n",
      "1   -0.602228\n",
      "dtype: float64\n",
      "The last two rows of the data series:\n",
      "2    0.022171\n",
      "3   -1.246760\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Head & Tail\n",
    "# To view a small sample of a Series or the DataFrame object, use the head() and the tail() methods.\n",
    "s = pd.Series(np.random.randn(4))\n",
    "print (\"The original series is:\")\n",
    "print (s)\n",
    "print (\"The first two rows of the data series:\")\n",
    "print (s.head(2))\n",
    "print (\"The last two rows of the data series:\")\n",
    "print (s.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Basic Functionality\n",
    "\n",
    "|Sr.No.\t| Attribute or Method & Description|\n",
    "|-|-|\n",
    "|1\t|T <br> Transposes rows and columns.|\n",
    "|2\t|axes <br> Returns a list with the row axis labels and column axis labels as the only members.|\n",
    "|3\t|dtypes <br> Returns the dtypes in this object.|\n",
    "|4\t|empty <br> True if NDFrame is entirely empty [no items]; if any of the axes are of length 0.|\n",
    "|5 |ndim <br> Number of axes / array dimensions.|\n",
    "|6 |shape <br> Returns a tuple representing the dimensionality of the DataFrame.|\n",
    "|7 |size <br> Number of elements in the NDFrame.|\n",
    "|8 |values <br> Numpy representation of NDFrame.|\n",
    "|9 |head() <br> Returns the first n rows.|\n",
    "|10 |tail() <br> Returns last n rows.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data series is:\n",
      "    Name  Age  Rating\n",
      "0    Tom   25    4.23\n",
      "1  James   26    3.24\n",
      "2  Ricky   25    3.98\n",
      "3    Vin   23    2.56\n",
      "4  Steve   30    3.20\n",
      "5  Smith   29    4.60\n",
      "6   Jack   23    3.80\n"
     ]
    }
   ],
   "source": [
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    "\n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"Our data series is:\")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transpose of the data series is:\n",
      "           0      1      2     3      4      5     6\n",
      "Name     Tom  James  Ricky   Vin  Steve  Smith  Jack\n",
      "Age       25     26     25    23     30     29    23\n",
      "Rating  4.23   3.24   3.98  2.56    3.2    4.6   3.8\n"
     ]
    }
   ],
   "source": [
    "# T (Transpose)\n",
    "# Returns the transpose of the DataFrame. The rows and columns will interchange.\n",
    "# Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"The transpose of the data series is:\")\n",
    "print (df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row axis labels and column axis labels are:\n",
      "[RangeIndex(start=0, stop=7, step=1), Index(['Name', 'Age', 'Rating'], dtype='object')]\n"
     ]
    }
   ],
   "source": [
    "# axes\n",
    "# Returns the list of row axis labels and column axis labels.\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    "\n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"Row axis labels and column axis labels are:\")\n",
    "print (df.axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data types of each column are:\n",
      "Name       object\n",
      "Age         int64\n",
      "Rating    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# dtypes\n",
    "# Returns the data type of each column.\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    "\n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"The data types of each column are:\")\n",
    "print (df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the object empty?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# empty\n",
    "# Returns the Boolean value saying whether the Object is empty or not; True indicates that the object is empty.\n",
    "\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    " \n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"Is the object empty?\")\n",
    "print (df.empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our object is:\n",
      "    Name  Age  Rating\n",
      "0    Tom   25    4.23\n",
      "1  James   26    3.24\n",
      "2  Ricky   25    3.98\n",
      "3    Vin   23    2.56\n",
      "4  Steve   30    3.20\n",
      "5  Smith   29    4.60\n",
      "6   Jack   23    3.80\n",
      "The dimension of the object is:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# ndim\n",
    "# Returns the number of dimensions of the object. By definition, DataFrame is a 2D object.\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    "\n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"Our object is:\")\n",
    "print (df)\n",
    "print (\"The dimension of the object is:\")\n",
    "print (df.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our object is:\n",
      "    Name  Age  Rating\n",
      "0    Tom   25    4.23\n",
      "1  James   26    3.24\n",
      "2  Ricky   25    3.98\n",
      "3    Vin   23    2.56\n",
      "4  Steve   30    3.20\n",
      "5  Smith   29    4.60\n",
      "6   Jack   23    3.80\n",
      "The shape of the object is:\n",
      "(7, 3)\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "# Returns a tuple representing the dimensionality of the DataFrame. \n",
    "# Tuple (a,b), where a represents the number of rows and b represents the number of columns.\n",
    "\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    " \n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"Our object is:\")\n",
    "print (df)\n",
    "print (\"The shape of the object is:\")\n",
    "print (df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our object is:\n",
      "    Name  Age  Rating\n",
      "0    Tom   25    4.23\n",
      "1  James   26    3.24\n",
      "2  Ricky   25    3.98\n",
      "3    Vin   23    2.56\n",
      "4  Steve   30    3.20\n",
      "5  Smith   29    4.60\n",
      "6   Jack   23    3.80\n",
      "The total number of elements in our object is:\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# size\n",
    "# Returns the number of elements in the DataFrame.\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    " \n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"Our object is:\")\n",
    "print (df)\n",
    "print (\"The total number of elements in our object is:\")\n",
    "print (df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our object is:\n",
      "    Name  Age  Rating\n",
      "0    Tom   25    4.23\n",
      "1  James   26    3.24\n",
      "2  Ricky   25    3.98\n",
      "3    Vin   23    2.56\n",
      "4  Steve   30    3.20\n",
      "5  Smith   29    4.60\n",
      "6   Jack   23    3.80\n",
      "The actual data in our data frame is:\n",
      "[['Tom' 25 4.23]\n",
      " ['James' 26 3.24]\n",
      " ['Ricky' 25 3.98]\n",
      " ['Vin' 23 2.56]\n",
      " ['Steve' 30 3.2]\n",
      " ['Smith' 29 4.6]\n",
      " ['Jack' 23 3.8]]\n"
     ]
    }
   ],
   "source": [
    "# values\n",
    "# Returns the actual data in the DataFrame as an NDarray.\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    " \n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"Our object is:\")\n",
    "print (df)\n",
    "print (\"The actual data in our data frame is:\")\n",
    "print (df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data frame is:\n",
      "    Name  Age  Rating\n",
      "0    Tom   25    4.23\n",
      "1  James   26    3.24\n",
      "2  Ricky   25    3.98\n",
      "3    Vin   23    2.56\n",
      "4  Steve   30    3.20\n",
      "5  Smith   29    4.60\n",
      "6   Jack   23    3.80\n",
      "The first two rows of the data frame is:\n",
      "    Name  Age  Rating\n",
      "0    Tom   25    4.23\n",
      "1  James   26    3.24\n",
      "The last two rows of the data frame is:\n",
      "    Name  Age  Rating\n",
      "5  Smith   29     4.6\n",
      "6   Jack   23     3.8\n"
     ]
    }
   ],
   "source": [
    "# Head & Tail\n",
    "# To view a small sample of a DataFrame object, use the head() and tail() methods.\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8])}\n",
    "\n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print (\"Our data frame is:\")\n",
    "print (df)\n",
    "print (\"The first two rows of the data frame is:\")\n",
    "print (df.head(2))\n",
    "print (\"The last two rows of the data frame is:\")\n",
    "print (df.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Python Pandas - Descriptive Statistics\n",
    "\n",
    "A large number of methods collectively compute descriptive statistics and other related operations on DataFrame. \n",
    "\n",
    "Most of these are aggregations like sum(), mean(), but some of them, like sumsum(), produce an object of the same size. \n",
    "\n",
    "Generally speaking, these methods take an axis argument, just like ndarray.{sum, std, ...}, but the axis can be specified by name or integer\n",
    "\n",
    "DataFrame − “index” (axis=0, default), “columns” (axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Rating\n",
      "0      Tom   25    4.23\n",
      "1    James   26    3.24\n",
      "2    Ricky   25    3.98\n",
      "3      Vin   23    2.56\n",
      "4    Steve   30    3.20\n",
      "5    Smith   29    4.60\n",
      "6     Jack   23    3.80\n",
      "7      Lee   34    3.78\n",
      "8    David   40    2.98\n",
      "9   Gasper   30    4.80\n",
      "10  Betina   51    4.10\n",
      "11  Andres   46    3.65\n"
     ]
    }
   ],
   "source": [
    "# Let us create a DataFrame and use this object throughout this chapter for all the operations.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack',\n",
    "   'Lee','David','Gasper','Betina','Andres']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23,34,40,30,51,46]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8,3.78,2.98,4.80,4.10,3.65])\n",
    "}\n",
    "\n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name      TomJamesRickyVinSteveSmithJackLeeDavidGasperBe...\n",
      "Age                                                     382\n",
      "Rating                                                44.92\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# sum()\n",
    "# Returns the sum of the values for the requested axis. \n",
    "# By default, axis is index (axis=0).\n",
    "#Create a Dictionary of series\n",
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Smith','Jack',\n",
    "   'Lee','David','Gasper','Betina','Andres']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23,34,40,30,51,46]),\n",
    "   'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8,3.78,2.98,4.80,4.10,3.65])\n",
    "}\n",
    "\n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print(df.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     29.23\n",
      "1     29.24\n",
      "2     28.98\n",
      "3     25.56\n",
      "4     33.20\n",
      "5     33.60\n",
      "6     26.80\n",
      "7     37.78\n",
      "8     42.98\n",
      "9     34.80\n",
      "10    55.10\n",
      "11    49.65\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# axis=1\n",
    "# This syntax will give the output as shown below.\n",
    "df = pd.DataFrame(d)\n",
    "print(df.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age       31.833333\n",
      "Rating     3.743333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# mean()\n",
    "# Returns the average value\n",
    "df = pd.DataFrame(d)\n",
    "print(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age       9.232682\n",
      "Rating    0.661628\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# std()\n",
    "# Returns the Bressel standard deviation of the numerical columns.\n",
    "df = pd.DataFrame(d)\n",
    "print(df.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1) Functions & Description\n",
    "Let us now understand the functions under Descriptive Statistics in Python Pandas. The following table list down the important functions −\n",
    "\n",
    "|Sr.No.\t|Function\t|Description|\n",
    "|-|-|-|\n",
    "|1\t|count()\t|Number of non-null observations|\n",
    "|2\t|sum()\t|Sum of values|\n",
    "|3\t|mean()\t|Mean of Values|\n",
    "|4\t|median()\t|Median of Values|\n",
    "|5\t|mode()\t|Mode of values|\n",
    "|6\t|std()\t|Standard Deviation of the Values|\n",
    "|7\t|min()\t|Minimum Value|\n",
    "|8\t|max()\t|Maximum Value|\n",
    "|9\t|abs()\t|Absolute Value|\n",
    "|10\t|prod()\t|Product of Values|\n",
    "|11\t|cumsum()\t|Cumulative Sum|\n",
    "|12\t|cumprod()\t|Cumulative Product|\n",
    "\n",
    "Functions like sum(), cumsum() work with both numeric and character (or) string data elements without any error. \n",
    "\n",
    "Though n practice, character aggregations are never used generally, these functions do not throw any exception.\n",
    "\n",
    "Functions like abs(), cumprod() throw exception when the DataFrame contains character or string data because such operations cannot be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Age     Rating\n",
      "count  12.000000  12.000000\n",
      "mean   31.833333   3.743333\n",
      "std     9.232682   0.661628\n",
      "min    23.000000   2.560000\n",
      "25%    25.000000   3.230000\n",
      "50%    29.500000   3.790000\n",
      "75%    35.500000   4.132500\n",
      "max    51.000000   4.800000\n"
     ]
    }
   ],
   "source": [
    "# Summarizing Data\n",
    "# The describe() function computes a summary of statistics pertaining to the DataFrame columns.\n",
    "df = pd.DataFrame(d)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives the mean, std and IQR values. \n",
    "\n",
    "And, function excludes the character columns and given summary about numeric columns. 'include' is the argument which is used to pass necessary information regarding what columns need to be considered for summarizing. \n",
    "\n",
    "Takes the list of values; by default, 'number'.\n",
    "\n",
    "object − Summarizes String columns\n",
    "\n",
    "number − Summarizes Numeric columns\n",
    "\n",
    "all − Summarizes all columns together (Should not pass it as a list value)\n",
    "\n",
    "Now, use the following statement in the program and check the output −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name\n",
      "count     12\n",
      "unique    12\n",
      "top     Jack\n",
      "freq       1\n"
     ]
    }
   ],
   "source": [
    "print(df.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name        Age     Rating\n",
      "count     12  12.000000  12.000000\n",
      "unique    12        NaN        NaN\n",
      "top     Jack        NaN        NaN\n",
      "freq       1        NaN        NaN\n",
      "mean     NaN  31.833333   3.743333\n",
      "std      NaN   9.232682   0.661628\n",
      "min      NaN  23.000000   2.560000\n",
      "25%      NaN  25.000000   3.230000\n",
      "50%      NaN  29.500000   3.790000\n",
      "75%      NaN  35.500000   4.132500\n",
      "max      NaN  51.000000   4.800000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Age     Rating\n",
      "count  12.000000  12.000000\n",
      "mean   31.833333   3.743333\n",
      "std     9.232682   0.661628\n",
      "min    23.000000   2.560000\n",
      "25%    25.000000   3.230000\n",
      "50%    29.500000   3.790000\n",
      "75%    35.500000   4.132500\n",
      "max    51.000000   4.800000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe(include='number'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age       31.833333\n",
      "Rating     3.743333\n",
      "Name: mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.describe(include='number').loc['mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Python Pandas - Function Application\n",
    "\n",
    "To apply your own or another library’s functions to Pandas objects, you should be aware of the three important methods. \n",
    "\n",
    "The methods have been discussed below. The appropriate method to use depends on whether your function expects to operate on an entire DataFrame, row- or column-wise, or element wise.\n",
    "\n",
    "- Table wise Function Application: pipe()\n",
    "- Row or Column Wise Function Application: apply()\n",
    "- Element wise Function Application: applymap()\n",
    "\n",
    "Custom operations can be performed by passing the function and the appropriate number of parameters as pipe arguments. Thus, operation is performed on the whole DataFrame.\n",
    "\n",
    "For example, add a value 2 to all the elements in the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0  1.913940 -1.253825  0.083235\n",
      "1 -0.662172 -0.182668 -0.109724\n",
      "2  1.984517 -0.464194  0.110963\n",
      "3  1.508906  0.585394 -1.886177\n",
      "4  1.480049 -1.346783  0.760450\n",
      "---------------\n",
      "       col1      col2      col3\n",
      "0  3.913940  0.746175  2.083235\n",
      "1  1.337828  1.817332  1.890276\n",
      "2  3.984517  1.535806  2.110963\n",
      "3  3.508906  2.585394  0.113823\n",
      "4  3.480049  0.653217  2.760450\n"
     ]
    }
   ],
   "source": [
    "def adder(ele1,ele2):\n",
    "   return ele1+ele2\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(5,3),columns=['col1','col2','col3'])\n",
    "print(df)\n",
    "print('---------------')\n",
    "print(df.pipe(adder,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1) Row or Column Wise Function Application\n",
    "Arbitrary functions can be applied along the axes of a DataFrame or Panel using the apply() method, which, like the descriptive statistics methods, takes an optional axis argument. \n",
    "\n",
    "By default, the operation performs column wise, taking each column as an array-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0  0.659650 -0.027919  0.097700\n",
      "1 -0.538469 -1.605197 -0.376595\n",
      "2 -1.581943  0.530840 -0.943131\n",
      "3  0.201015  1.977503  1.212939\n",
      "4  0.391447  0.235031  0.715727\n",
      "----------\n",
      "col1   -0.173660\n",
      "col2    0.222052\n",
      "col3    0.141328\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5,3),columns=['col1','col2','col3'])\n",
    "print(df)\n",
    "print('----------')\n",
    "print(df.apply(np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0 -0.419601 -0.584702  2.213787\n",
      "1 -0.016674  0.463008  2.181432\n",
      "2 -0.272618  1.238778  0.905509\n",
      "3  0.977969  1.151887  1.159171\n",
      "4 -1.331923  1.387525 -0.183433\n",
      "----------\n",
      "0    0.403162\n",
      "1    0.875922\n",
      "2    0.623890\n",
      "3    1.096342\n",
      "4   -0.042610\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# By passing axis parameter, operations can be performed row wise.\n",
    "df = pd.DataFrame(np.random.randn(5,3),columns=['col1','col2','col3'])\n",
    "print(df)\n",
    "print('----------')\n",
    "print(df.apply(np.mean,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0 -1.234123  0.741644  1.054229\n",
      "1 -3.086060  1.101233  0.351777\n",
      "2  0.053133  0.635425 -0.353082\n",
      "3  0.410869 -1.892197 -0.625813\n",
      "4  0.294298  0.163654  1.864004\n",
      "----------\n",
      "col1    3.496928\n",
      "col2    2.993430\n",
      "col3    2.489817\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5,3),columns=['col1','col2','col3'])\n",
    "print(df)\n",
    "print('----------')\n",
    "print(df.apply(lambda x: x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2) Element Wise Function Application\n",
    "Not all functions can be vectorized <br>\n",
    "(neither the NumPy arrays which return another array nor any value), \n",
    "\n",
    "the methods applymap() on DataFrame \n",
    "\n",
    "and analogously map() on Series \n",
    "\n",
    "accept any Python function taking a single value and returning a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0 -1.018312  0.908817  0.055768\n",
      "1  0.620019 -0.863014 -0.232023\n",
      "2  0.577737  0.354875  0.216955\n",
      "3 -0.771666 -0.373549  0.315801\n",
      "4  0.314559 -0.548544  0.943734\n",
      "----------\n",
      "0   -101.831205\n",
      "1     62.001871\n",
      "2     57.773666\n",
      "3    -77.166569\n",
      "4     31.455869\n",
      "Name: col1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5,3),columns=['col1','col2','col3'])\n",
    "print(df)\n",
    "print('----------')\n",
    "# My custom function\n",
    "print(df['col1'].map(lambda x:x*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0 -0.312702  0.203102  0.786745\n",
      "1  0.102080 -1.600120 -0.014638\n",
      "2  0.781406 -0.509548  0.779168\n",
      "3 -0.987532  0.944156  0.602379\n",
      "4  1.556662  1.100223 -0.676889\n",
      "----------\n",
      "         col1        col2       col3\n",
      "0  -31.270225   20.310152  78.674451\n",
      "1   10.208040 -160.012004  -1.463849\n",
      "2   78.140562  -50.954839  77.916843\n",
      "3  -98.753237   94.415650  60.237946\n",
      "4  155.666230  110.022277 -67.688942\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5,3),columns=['col1','col2','col3'])\n",
    "print(df)\n",
    "print('----------')\n",
    "print(df.applymap(lambda x:x*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Python Pandas - Reindexing\n",
    "\n",
    "Reindexing changes the row labels and column labels of a DataFrame. \n",
    "\n",
    "To reindex means to conform the data to match a given set of labels along a particular axis.\n",
    "\n",
    "Multiple operations can be accomplished through indexing like −\n",
    "\n",
    "Reorder the existing data to match a new set of labels.\n",
    "\n",
    "Insert missing value (NA) markers in label locations where no data for the label existed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A       C   B\n",
      "0 2016-01-01    High NaN\n",
      "2 2016-01-03    High NaN\n",
      "5 2016-01-06  Medium NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "N=20\n",
    "\n",
    "df = pd.DataFrame({\n",
    "   'A': pd.date_range(start='2016-01-01',periods=N,freq='D'),\n",
    "   'x': np.linspace(0,stop=N-1,num=N),\n",
    "   'y': np.random.rand(N),\n",
    "   'C': np.random.choice(['Low','Medium','High'],N).tolist(),\n",
    "   'D': np.random.normal(100, 10, size=(N)).tolist()\n",
    "})\n",
    "\n",
    "#reindex the DataFrame\n",
    "df_reindexed = df.reindex(index=[0,2,5], columns=['A', 'C', 'B'])\n",
    "\n",
    "print(df_reindexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1) Reindex to Align with Other Objects\n",
    "You may wish to take an object and reindex its axes to be labeled the same as another object. Consider the following example to understand the same.\n",
    "\n",
    "Here, the df1 DataFrame is altered and reindexed like df2. \n",
    "\n",
    "The column names should be matched or else NAN will be added for the entire column label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0  1.206518 -0.951724  0.115935\n",
      "1 -0.513212  1.469051  0.163935\n",
      "2 -0.976731  0.434842 -0.608216\n",
      "3 -1.079990  1.213452 -0.397083\n",
      "4  0.496757  2.049719  1.034744\n",
      "5 -0.638728 -0.307256  1.221415\n",
      "6 -0.508381  0.053515 -1.646328\n",
      "7 -0.414141 -0.008552  1.307207\n",
      "8  0.966929  0.677408 -0.694104\n",
      "9 -2.015466 -2.130360  0.736448\n",
      "------\n",
      "       col1      col2      col3\n",
      "0  1.206518 -0.951724  0.115935\n",
      "1 -0.513212  1.469051  0.163935\n",
      "2 -0.976731  0.434842 -0.608216\n",
      "3 -1.079990  1.213452 -0.397083\n",
      "4  0.496757  2.049719  1.034744\n",
      "5 -0.638728 -0.307256  1.221415\n",
      "6 -0.508381  0.053515 -1.646328\n",
      "------\n",
      "       col1      col2\n",
      "0  1.206518 -0.951724\n",
      "1 -0.513212  1.469051\n",
      "------\n",
      "       col1      col2  col3  col4\n",
      "0  1.206518 -0.951724   NaN   NaN\n",
      "1 -0.513212  1.469051   NaN   NaN\n",
      "2       NaN       NaN   NaN   NaN\n",
      "3       NaN       NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(10,3),columns=['col1','col2','col3'])\n",
    "df2 = pd.DataFrame(np.random.randn(7,3),columns=['col1','col2','col3'])\n",
    "df3 = pd.DataFrame(np.random.randn(2,2),columns=['col1','col2'])\n",
    "df4 = pd.DataFrame(np.random.randn(4,4),columns=['col1','col2','col3','col4'])\n",
    "print(df1)\n",
    "print('------')\n",
    "df1 = df1.reindex_like(df2)\n",
    "print(df1)\n",
    "print('------')\n",
    "df1 = df1.reindex_like(df3)\n",
    "print(df1)\n",
    "print('------')\n",
    "df1 = df1.reindex_like(df4)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2) Filling while ReIndexing\n",
    "\n",
    "reindex() takes an optional parameter method which is a filling method with values as follows −\n",
    "\n",
    "pad/ffill − Fill values forward\n",
    "\n",
    "bfill/backfill − Fill values backward\n",
    "\n",
    "nearest − Fill from the nearest index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0  1.180596 -1.979792  0.979817\n",
      "1  0.652017  0.427577 -1.281322\n",
      "2       NaN       NaN       NaN\n",
      "3       NaN       NaN       NaN\n",
      "4       NaN       NaN       NaN\n",
      "5       NaN       NaN       NaN\n",
      "Data Frame with Forward Fill:\n",
      "       col1      col2      col3\n",
      "0  1.180596 -1.979792  0.979817\n",
      "1  0.652017  0.427577 -1.281322\n",
      "2  0.652017  0.427577 -1.281322\n",
      "3  0.652017  0.427577 -1.281322\n",
      "4  0.652017  0.427577 -1.281322\n",
      "5  0.652017  0.427577 -1.281322\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(6,3),columns=['col1','col2','col3'])\n",
    "df2 = pd.DataFrame(np.random.randn(2,3),columns=['col1','col2','col3'])\n",
    "\n",
    "# Padding NAN's\n",
    "print (df2.reindex_like(df1))\n",
    "\n",
    "# Now Fill the NAN's with preceding Values\n",
    "print (\"Data Frame with Forward Fill:\")\n",
    "print (df2.reindex_like(df1,method='ffill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3) Limits on Filling while Reindexing\n",
    "\n",
    "The limit argument provides additional control over filling while reindexing. \n",
    "\n",
    "Limit specifies the maximum count of consecutive matches. \n",
    "\n",
    "Let us consider the following example to understand the same −\n",
    "\n",
    "Note − Observe, only the 7th row is filled by the preceding 6th row. Then, the rows are left as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0 -1.882952 -0.722276 -0.566703\n",
      "1 -1.319018 -1.163026 -0.694021\n",
      "2       NaN       NaN       NaN\n",
      "3       NaN       NaN       NaN\n",
      "4       NaN       NaN       NaN\n",
      "5       NaN       NaN       NaN\n",
      "Data Frame with Forward Fill limiting to 1:\n",
      "       col1      col2      col3\n",
      "0 -1.882952 -0.722276 -0.566703\n",
      "1 -1.319018 -1.163026 -0.694021\n",
      "2 -1.319018 -1.163026 -0.694021\n",
      "3       NaN       NaN       NaN\n",
      "4       NaN       NaN       NaN\n",
      "5       NaN       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(6,3),columns=['col1','col2','col3'])\n",
    "df2 = pd.DataFrame(np.random.randn(2,3),columns=['col1','col2','col3'])\n",
    "\n",
    "# Padding NAN's\n",
    "print (df2.reindex_like(df1))\n",
    "\n",
    "# Now Fill the NAN's with preceding Values\n",
    "print (\"Data Frame with Forward Fill limiting to 1:\")\n",
    "print (df2.reindex_like(df1,method='ffill',limit=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4) Renaming\n",
    "The rename() method allows you to relabel an axis based on some mapping (a dict or Series) or an arbitrary function.\n",
    "\n",
    "Let us consider the following example to understand this −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3\n",
      "0 -0.196776 -0.834282 -1.129571\n",
      "1 -0.511678 -0.782796  0.089167\n",
      "2 -0.391352 -0.569292  0.718482\n",
      "3  0.284758 -0.843523 -0.172946\n",
      "4  0.401410  0.999131 -0.594649\n",
      "5 -0.069883 -1.766336 -1.764387\n",
      "After renaming the rows and columns:\n",
      "              c1        c2      col3\n",
      "apple  -0.196776 -0.834282 -1.129571\n",
      "banana -0.511678 -0.782796  0.089167\n",
      "durian -0.391352 -0.569292  0.718482\n",
      "3       0.284758 -0.843523 -0.172946\n",
      "4       0.401410  0.999131 -0.594649\n",
      "5      -0.069883 -1.766336 -1.764387\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(6,3),columns=['col1','col2','col3'])\n",
    "print (df1)\n",
    "\n",
    "print (\"After renaming the rows and columns:\")\n",
    "print (df1.rename(columns={'col1' : 'c1', 'col2' : 'c2'},\n",
    "index = {0 : 'apple', 1 : 'banana', 2 : 'durian'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Python Pandas - Iteration\n",
    "\n",
    "The behavior of basic iteration over Pandas objects depends on the type. \n",
    "\n",
    "When iterating over a Series, it is regarded as array-like, and basic iteration produces the values. Other data structures, like DataFrame and Panel, follow the dict-like convention of iterating over the keys of the objects.\n",
    "\n",
    "In short, basic iteration (for i in object) produces −\n",
    "\n",
    "Series − values\n",
    "\n",
    "DataFrame − column labels\n",
    "\n",
    "Panel − item labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating a DataFrame\n",
    "Iterating a DataFrame gives column names. Let us consider the following example to understand the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "x\n",
      "y\n",
      "C\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "N=20\n",
    "df = pd.DataFrame({\n",
    "   'A': pd.date_range(start='2016-01-01',periods=N,freq='D'),\n",
    "   'x': np.linspace(0,stop=N-1,num=N),\n",
    "   'y': np.random.rand(N),\n",
    "   'C': np.random.choice(['Low','Medium','High'],N).tolist(),\n",
    "   'D': np.random.normal(100, 10, size=(N)).tolist()\n",
    "   })\n",
    "\n",
    "for col in df:\n",
    "   print (col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iteritems()\n",
    "Iterates over each column as key, value pair with label as key and column value as a Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1 0    0.516344\n",
      "1    0.373297\n",
      "2   -1.359600\n",
      "3   -0.457608\n",
      "Name: col1, dtype: float64\n",
      "col2 0    0.275769\n",
      "1    2.138695\n",
      "2   -1.307691\n",
      "3    1.727049\n",
      "Name: col2, dtype: float64\n",
      "col3 0   -0.588594\n",
      "1    1.619734\n",
      "2    0.195442\n",
      "3    0.522783\n",
      "Name: col3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(4,3),columns=['col1','col2','col3'])\n",
    "for key,value in df.iteritems():\n",
    "   print (key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterrows()\n",
    "iterrows() returns the iterator yielding each index value along with a series containing the data in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 col1    1.742466\n",
      "col2   -0.190905\n",
      "col3   -0.688590\n",
      "Name: 0, dtype: float64\n",
      "1 col1    0.176350\n",
      "col2    0.361827\n",
      "col3   -0.204579\n",
      "Name: 1, dtype: float64\n",
      "2 col1   -2.227340\n",
      "col2   -0.158842\n",
      "col3   -2.192448\n",
      "Name: 2, dtype: float64\n",
      "3 col1    0.142847\n",
      "col2   -0.483820\n",
      "col3   -0.158134\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(4,3),columns = ['col1','col2','col3'])\n",
    "for row_index,row in df.iterrows():\n",
    "   print (row_index,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## itertuples()\n",
    "itertuples() method will return an iterator yielding a named tuple for each row in the DataFrame. \n",
    "\n",
    "The first element of the tuple will be the row’s corresponding index value, while the remaining values are the row values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=0, col1=-0.46972328579244405, col2=3.143296503210067, col3=-0.039911479524954746)\n",
      "Pandas(Index=1, col1=1.2272742934665708, col2=1.5879282796288032, col3=-0.24122426168704922)\n",
      "Pandas(Index=2, col1=0.1916165555742965, col2=1.1366746114348907, col3=0.16655503325078297)\n",
      "Pandas(Index=3, col1=2.771346027772093, col2=0.8603069676375422, col3=0.9517625234075735)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(4,3),columns = ['col1','col2','col3'])\n",
    "for row in df.itertuples():\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Python Pandas - Sorting\n",
    "\n",
    "There are two kinds of sorting available in Pandas. They are −\n",
    "\n",
    "- By label\n",
    "- By Actual Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col2      col1\n",
      "1  0.761392 -0.019561\n",
      "4 -1.502611  1.650270\n",
      "6  1.051382  0.124045\n",
      "2 -1.995197  0.273147\n",
      "3  0.432691  1.035238\n",
      "5  0.045451 -0.033926\n",
      "9  0.088644 -0.551866\n",
      "8 -1.107953  0.116830\n",
      "0 -0.689022 -0.898038\n",
      "7  1.112481 -1.721484\n"
     ]
    }
   ],
   "source": [
    "unsorted_df=pd.DataFrame(np.random.randn(10,2),index=[1,4,6,2,3,5,9,8,0,7],columns=['col2','col1'])\n",
    "print (unsorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Label\n",
    "Using the sort_index() method, by passing the axis arguments and the order of sorting, DataFrame can be sorted. By default, sorting is done on row labels in ascending orde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col2      col1\n",
      "0 -0.629999  0.015565\n",
      "1  0.962501  0.008565\n",
      "2 -0.858136 -0.587373\n",
      "3  0.680760  0.197507\n",
      "4  0.255097  1.449897\n",
      "5 -0.867368 -0.544947\n",
      "6  1.654593  1.891764\n",
      "7 -0.076118  0.072947\n",
      "8 -2.581441 -2.016118\n",
      "9 -0.158631 -0.204769\n"
     ]
    }
   ],
   "source": [
    "unsorted_df = pd.DataFrame(np.random.randn(10,2),index=[1,4,6,2,3,5,9,8,0,7],columns = ['col2','col1'])\n",
    "\n",
    "sorted_df=unsorted_df.sort_index()\n",
    "print (sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order of Sorting\n",
    "By passing the Boolean value to ascending parameter, the order of the sorting can be controlled. Let us consider the following example to understand the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col2      col1\n",
      "9  0.320175  0.717297\n",
      "8  1.313146 -1.854825\n",
      "7  0.741328 -0.707559\n",
      "6 -0.873185  0.609666\n",
      "5 -1.409327 -0.939388\n",
      "4  0.493388 -1.195138\n",
      "3  0.806810  0.681326\n",
      "2 -0.259036  0.435611\n",
      "1  0.352179  0.887263\n",
      "0  0.095931 -0.800361\n"
     ]
    }
   ],
   "source": [
    "unsorted_df = pd.DataFrame(np.random.randn(10,2),index=[1,4,6,2,3,5,9,8,0,7],columns = ['col2','col1'])\n",
    "\n",
    "sorted_df = unsorted_df.sort_index(ascending=False)\n",
    "print (sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort the Columns\n",
    "By passing the axis argument with a value 0 or 1, the sorting can be done on the column labels. By default, axis=0, sort by row. Let us consider the following example to understand the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2\n",
      "1  0.041546 -0.517166\n",
      "4 -0.806516  0.640516\n",
      "6 -1.273199  2.095434\n",
      "2  1.251439  0.137462\n",
      "3  0.694747  0.576557\n",
      "5  0.756727  0.087464\n",
      "9  1.181048 -0.900617\n",
      "8  1.474624  0.392552\n",
      "0  0.668391  0.318459\n",
      "7 -0.598738 -0.694271\n"
     ]
    }
   ],
   "source": [
    "unsorted_df = pd.DataFrame(np.random.randn(10,2),index=[1,4,6,2,3,5,9,8,0,7],columns = ['col2','col1'])\n",
    " \n",
    "sorted_df=unsorted_df.sort_index(axis=1)\n",
    "\n",
    "print (sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Value\n",
    "Like index sorting, sort_values() is the method for sorting by values. It accepts a 'by' argument which will use the column name of the DataFrame with which the values are to be sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "1     1     3\n",
      "2     1     2\n",
      "3     1     4\n",
      "0     2     1\n"
     ]
    }
   ],
   "source": [
    "unsorted_df = pd.DataFrame({'col1':[2,1,1,1],'col2':[1,3,2,4]})\n",
    "sorted_df = unsorted_df.sort_values(by='col1')\n",
    "\n",
    "print (sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe, col1 values are sorted and the respective col2 value and row index will alter along with col1. Thus, they look unsorted.\n",
    "\n",
    "'by' argument takes a list of column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "2     1     2\n",
      "1     1     3\n",
      "3     1     4\n",
      "0     2     1\n"
     ]
    }
   ],
   "source": [
    "unsorted_df = pd.DataFrame({'col1':[2,1,1,1],'col2':[1,3,2,4]})\n",
    "sorted_df = unsorted_df.sort_values(by=['col1','col2'])\n",
    "\n",
    "print (sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Algorithm\n",
    "sort_values() provides a provision to choose the algorithm from mergesort, heapsort and quicksort. \n",
    "\n",
    "Mergesort is the only stable algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "1     1     3\n",
      "2     1     2\n",
      "3     1     4\n",
      "0     2     1\n"
     ]
    }
   ],
   "source": [
    "unsorted_df = pd.DataFrame({'col1':[2,1,1,1],'col2':[1,3,2,4]})\n",
    "sorted_df = unsorted_df.sort_values(by='col1' ,kind='mergesort')\n",
    "\n",
    "print (sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11) Python Pandas - Working with Text Data\n",
    "\n",
    "Pandas provides a set of string functions which make it easy to operate on string data. Most importantly, these functions ignore (or exclude) missing/NaN values.\n",
    "\n",
    "|Sr.No|\tFunction & Description|\n",
    "|-|-|\n",
    "|1\t|lower() Converts strings in the Series/Index to lower case.|\n",
    "|2\t|upper() Converts strings in the Series/Index to upper case.|\n",
    "|3\t|len() Computes String length().|\n",
    "|4\t|strip()Helps strip whitespace(including newline) from each string in the Series/index from both the sides.|\n",
    "|5\t|split(' ') Splits each string with the given pattern.|\n",
    "|6\t|cat(sep=' ') Concatenates the series/index elements with given separator.|\n",
    "|7\t|get_dummies() Returns the DataFrame with One-Hot Encoded values.|\n",
    "|8\t|contains(pattern) Returns a Boolean value True for each element if the substring contains in the element, else False.|\n",
    "|9\t|replace(a,b) Replaces the value a with the value b.|\n",
    "|10\t|repeat(value) Repeats each element with specified number of times.|\n",
    "|11\t|count(pattern) Returns count of appearance of pattern in each element.|\n",
    "|12\t|startswith(pattern) Returns true if the element in the Series/Index starts with the pattern.|\n",
    "|13\t|endswith(pattern) Returns true if the element in the Series/Index ends with the pattern.|\n",
    "|14\t|find(pattern) Returns the first position of the first occurrence of the pattern.|\n",
    "|15\t|findall(pattern) Returns a list of all occurrence of the pattern.|\n",
    "|16\t|swapcase Swaps the case lower/upper.|\n",
    "|17\t|islower() Checks whether all characters in each string in the Series/Index in lower case or not. Returns Boolean|\n",
    "|18\t|isupper() Checks whether all characters in each string in the Series/Index in upper case or not. Returns Boolean.|\n",
    "|19\t|isnumeric() Checks whether all characters in each string in the Series/Index are numeric. Returns Boolean|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             tom\n",
      "1    william rick\n",
      "2            john\n",
      "3         alber@t\n",
      "4             NaN\n",
      "5            1234\n",
      "6      stevesmith\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# lower()\n",
    "s = pd.Series(['Tom', 'William Rick', 'John', 'Alber@t', np.nan, '1234','SteveSmith'])\n",
    "print (s.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             TOM\n",
      "1    WILLIAM RICK\n",
      "2            JOHN\n",
      "3         ALBER@T\n",
      "4             NaN\n",
      "5            1234\n",
      "6      STEVESMITH\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# upper()\n",
    "print (s.str.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3.0\n",
      "1    12.0\n",
      "2     4.0\n",
      "3     7.0\n",
      "4     NaN\n",
      "5     4.0\n",
      "6    10.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# len()\n",
    "print (s.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Tom \n",
      "1     William Rick\n",
      "2             John\n",
      "3          Alber@t\n",
      "dtype: object\n",
      "After Stripping:\n",
      "0             Tom\n",
      "1    William Rick\n",
      "2            John\n",
      "3         Alber@t\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# strip()\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "print (s)\n",
    "print (\"After Stripping:\")\n",
    "print (s.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Tom \n",
      "1     William Rick\n",
      "2             John\n",
      "3          Alber@t\n",
      "dtype: object\n",
      "Split Pattern:\n",
      "0              [Tom, ]\n",
      "1    [, William, Rick]\n",
      "2               [John]\n",
      "3            [Alber@t]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# split(pattern)\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "print (s)\n",
    "print (\"Split Pattern:\")\n",
    "print (s.str.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom _ William Rick_John_Alber@t\n"
     ]
    }
   ],
   "source": [
    "# cat(sep=pattern)\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "print (s.str.cat(sep='_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    William Rick  Alber@t  John  Tom \n",
      "0              0        0     0     1\n",
      "1              1        0     0     0\n",
      "2              0        0     1     0\n",
      "3              0        1     0     0\n"
     ]
    }
   ],
   "source": [
    "# get_dummies()\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "\n",
    "print (s.str.get_dummies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# contains ()\n",
    "\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "\n",
    "print (s.str.contains(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Tom \n",
      "1     William Rick\n",
      "2             John\n",
      "3          Alber@t\n",
      "dtype: object\n",
      "After replacing @ with $:\n",
      "0             Tom \n",
      "1     William Rick\n",
      "2             John\n",
      "3          Alber$t\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# replace(a,b)\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "print (s)\n",
    "print (\"After replacing @ with $:\")\n",
    "print (s.str.replace('@','$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      Tom Tom \n",
      "1     William Rick William Rick\n",
      "2                      JohnJohn\n",
      "3                Alber@tAlber@t\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# repeat(value)\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "\n",
    "print (s.str.repeat(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 'm's in each string:\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count(pattern) \n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "print (\"The number of 'm's in each string:\")\n",
    "print (s.str.count('m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings that start with 'T':\n",
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# startswith(pattern)\n",
    "\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "\n",
    "print (\"Strings that start with 'T':\")\n",
    "print (s.str. startswith ('T'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings that end with 't':\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# endswith(pattern)\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "\n",
    "print (\"Strings that end with 't':\")\n",
    "print (s.str.endswith('t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -1\n",
      "1   -1\n",
      "2   -1\n",
      "3    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# find(pattern)\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "\n",
    "print (s.str.find('e'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     []\n",
      "1     []\n",
      "2     []\n",
      "3    [e]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# findall(pattern)\n",
    "\n",
    "s = pd.Series(['Tom ', ' William Rick', 'John', 'Alber@t'])\n",
    "\n",
    "print (s.str.findall('e'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             tOM\n",
      "1    wILLIAM rICK\n",
      "2            jOHN\n",
      "3         aLBER@T\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# swapcase()\n",
    "\n",
    "s = pd.Series(['Tom', 'William Rick', 'John', 'Alber@t'])\n",
    "print (s.str.swapcase())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# islower()\n",
    "\n",
    "s = pd.Series(['Tom', 'William Rick', 'John', 'Alber@t'])\n",
    "print (s.str.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# isupper()\n",
    "\n",
    "s = pd.Series(['Tom', 'William Rick', 'John', 'Alber@t'])\n",
    "\n",
    "print (s.str.isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# snumeric()\n",
    "\n",
    "s = pd.Series(['Tom', 'William Rick', 'John', 'Alber@t'])\n",
    "\n",
    "print (s.str.isnumeric())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12) Python Pandas - Options and Customization\n",
    "\n",
    "Pandas provide API to customize some aspects of its behavior, display is being mostly used.\n",
    "\n",
    "The API is composed of five relevant functions. They are −\n",
    "\n",
    "- get_option()\n",
    "- set_option()\n",
    "- reset_option()\n",
    "- describe_option()\n",
    "- option_context()\n",
    "\n",
    "Let us now understand how the functions operate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display.max_rows\n",
    "Displays the default number of value. Interpreter reads this value and displays the rows with this value as upper limit to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print (pd.get_option(\"display.max_rows\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display.max_columns\n",
    "Displays the default number of value. Interpreter reads this value and displays the rows with this value as upper limit to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print (pd.get_option(\"display.max_columns\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, 60 and 20 are the default configuration parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set_option(param,value)\n",
    "set_option takes two arguments and sets the value to the parameter as shown below −\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\",80)\n",
    "print (pd.get_option(\"display.max_rows\"))\n",
    "\n",
    "pd.set_option(\"display.max_columns\",30)\n",
    "print (pd.get_option(\"display.max_columns\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reset_option(param)\n",
    "reset_option takes an argument and sets the value back to the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "pd.reset_option(\"display.max_rows\")\n",
    "print (pd.get_option(\"display.max_rows\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe_option(param)\n",
    "describe_option prints the description of the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display.max_rows : int\n",
      "    If max_rows is exceeded, switch to truncate view. Depending on\n",
      "    `large_repr`, objects are either centrally truncated or printed as\n",
      "    a summary view. 'None' value means unlimited.\n",
      "\n",
      "    In case python/IPython is running in a terminal and `large_repr`\n",
      "    equals 'truncate' this can be set to 0 and pandas will auto-detect\n",
      "    the height of the terminal and print a truncated object which fits\n",
      "    the screen height. The IPython notebook, IPython qtconsole, or\n",
      "    IDLE do not run in a terminal and hence it is not possible to do\n",
      "    correct auto-detection.\n",
      "    [default: 60] [currently: 60]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.describe_option(\"display.max_rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option_context()\n",
    "option_context context manager is used to set the option in with statement temporarily. Option values are restored automatically when you exit the with block −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with pd.option_context(\"display.max_rows\",10):\n",
    "   print(pd.get_option(\"display.max_rows\"))\n",
    "   print(pd.get_option(\"display.max_rows\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13) Python Pandas - Indexing and Selecting Data\n",
    "\n",
    "|Sr.No|\tIndexing & Description|\n",
    "|-|-|\n",
    "|1|\t.loc() Label based|\n",
    "|2|\t.iloc() Integer based|\n",
    "|3|\t.ix() Both Label and Integer based|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .loc()\n",
    "Pandas provide various methods to have purely label based indexing. When slicing, the start bound is also included. \n",
    "\n",
    "Integers are valid labels, but they refer to the label and not the position.\n",
    "\n",
    ".loc() has multiple access methods like −\n",
    "\n",
    "- A single scalar label\n",
    "- A list of labels\n",
    "- A slice object\n",
    "- A Boolean array\n",
    "\n",
    "loc takes two single/list/range operator separated by ','. The first one indicates the row and the second one indicates columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "a -1.020798 -0.029458  0.206830 -0.020901\n",
      "b -1.107771  0.424096  1.647831  0.682213\n",
      "c -1.065031 -0.003648  2.348542 -1.955054\n",
      "d  0.994695  1.643610 -0.871996 -0.832421\n",
      "e -0.256169 -0.429726 -0.169313  0.746175\n",
      "f  0.509702  0.615902 -1.663595 -0.346689\n",
      "g -1.259744  0.972789  1.330269 -0.369581\n",
      "h -1.287598  0.107915 -0.847324 -0.785353\n",
      "--------\n",
      "a   -1.020798\n",
      "b   -1.107771\n",
      "c   -1.065031\n",
      "d    0.994695\n",
      "e   -0.256169\n",
      "f    0.509702\n",
      "g   -1.259744\n",
      "h   -1.287598\n",
      "Name: A, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4),\n",
    "index = ['a','b','c','d','e','f','g','h'], \n",
    "columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print(df)\n",
    "print('--------')\n",
    "#select all rows for a specific column\n",
    "print (df.loc[:,'A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "a  1.150000 -0.898224  0.863379  0.699173\n",
      "b -1.595967  0.713396  0.099974  0.861035\n",
      "c  1.375809 -0.288982  1.596301 -0.301298\n",
      "d  0.163590 -0.566750 -0.668633  0.425196\n",
      "e  2.647472 -0.359073  0.683268 -1.121585\n",
      "f -0.248587  0.645296 -0.095332 -1.016485\n",
      "g -2.905046 -0.639556  0.849662  0.822721\n",
      "h  1.447635 -0.651279 -1.913767 -1.099592\n",
      "--------\n",
      "          A         C\n",
      "a  1.150000  0.863379\n",
      "b -1.595967  0.099974\n",
      "c  1.375809  1.596301\n",
      "d  0.163590 -0.668633\n",
      "e  2.647472  0.683268\n",
      "f -0.248587 -0.095332\n",
      "g -2.905046  0.849662\n",
      "h  1.447635 -1.913767\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4),\n",
    "index = ['a','b','c','d','e','f','g','h'], columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print(df)\n",
    "print('--------')\n",
    "# Select all rows for multiple columns, say list[]\n",
    "print (df.loc[:,['A','C']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "a -0.640647 -3.093143 -0.018874 -1.070931\n",
      "b  1.231457 -0.307357  0.622364 -0.950260\n",
      "c  0.320567 -1.030685  0.211068 -0.035858\n",
      "d  1.932144  1.893074 -0.770702 -1.624783\n",
      "e -0.697368 -0.046149  1.221530 -0.402800\n",
      "f -0.055203 -0.711767  0.003873 -1.363633\n",
      "g  2.016985 -1.369475  1.036261  1.587503\n",
      "h -0.040226 -0.276718  0.039878 -1.862235\n",
      "--------\n",
      "          A         C\n",
      "a -0.640647 -0.018874\n",
      "b  1.231457  0.622364\n",
      "f -0.055203  0.003873\n",
      "h -0.040226  0.039878\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4),\n",
    "index = ['a','b','c','d','e','f','g','h'], columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print(df)\n",
    "print('--------')\n",
    "# Select few rows for multiple columns, say list[]\n",
    "print (df.loc[['a','b','f','h'],['A','C']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "a  1.978900  0.394523  0.334851  1.039620\n",
      "b -0.488421 -0.652538  0.745068  0.645888\n",
      "c  1.499717  0.035280 -0.612156 -0.463610\n",
      "d -0.598905 -1.419700  0.717117 -0.749653\n",
      "e  1.755266  2.560890  0.971560 -1.086996\n",
      "f -0.544616 -0.229698  1.099470 -0.314157\n",
      "g -0.524589 -0.272378  0.598330 -1.413835\n",
      "h  0.960530 -1.427705  0.141867  0.657470\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4),\n",
    "index = ['a','b','c','d','e','f','g','h'], columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "# Select range of rows for all columns\n",
    "print (df.loc['a':'h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "a  0.753313  0.918280 -0.280508  1.117732\n",
      "b -0.903197  0.895804 -0.793415 -1.642170\n",
      "c -0.941159  0.978717  1.849053  0.070323\n",
      "d -1.568304 -1.314637 -0.617569  1.449242\n",
      "e  1.747597  0.066807  0.364509 -0.252929\n",
      "f -0.445130 -1.178216 -2.029896 -1.376230\n",
      "g -1.178876 -1.099641  0.659298 -1.203584\n",
      "h  0.191390  0.288599 -1.737058 -0.055012\n",
      "--------\n",
      "A     True\n",
      "B     True\n",
      "C    False\n",
      "D     True\n",
      "Name: a, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4),\n",
    "index = ['a','b','c','d','e','f','g','h'], columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print(df)\n",
    "print('--------')\n",
    "# for getting values with a boolean array\n",
    "print (df.loc['a']>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .iloc()\n",
    "Pandas provide various methods in order to get purely integer based indexing. Like python and numpy, these are 0-based indexing.\n",
    "\n",
    "The various access methods are as follows −\n",
    "\n",
    "- An Integer\n",
    "- A list of integers\n",
    "- A range of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "0  0.602804  0.335743 -1.557700 -0.390637\n",
      "1 -1.424392  0.262525  0.506933  1.001640\n",
      "2  0.258066 -0.266593  0.356324 -1.956094\n",
      "3  1.097986 -1.312778  0.722474 -0.796931\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "# select all rows for a specific column\n",
    "print (df.iloc[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D\n",
      "0  1.320969  0.211881  0.014616  0.719239\n",
      "1 -0.401055  0.773753  0.148393 -0.075941\n",
      "2  2.745113  1.390188 -1.184141  0.710436\n",
      "3  0.171308 -1.020253 -0.865727 -0.031211\n",
      "          C         D\n",
      "1  0.148393 -0.075941\n",
      "2 -1.184141  0.710436\n",
      "3 -0.865727 -0.031211\n",
      "4  0.505860  1.015835\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "# Integer slicing\n",
    "print (df.iloc[:4])\n",
    "print (df.iloc[1:5, 2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          B         D\n",
      "1  0.920923 -0.050724\n",
      "3 -0.424778 -0.233053\n",
      "5  0.916433  0.750110\n",
      "          A         B         C         D\n",
      "1 -0.166419  0.920923 -0.110296 -0.050724\n",
      "2  1.660913  0.975492 -1.541172  0.613906\n",
      "          B         C\n",
      "0 -0.169770 -1.631414\n",
      "1  0.920923 -0.110296\n",
      "2  0.975492 -1.541172\n",
      "3 -0.424778  0.330001\n",
      "4 -1.108625 -1.942132\n",
      "5  0.916433 -1.548272\n",
      "6 -0.978517  0.392011\n",
      "7 -1.044161  0.050906\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "# Slicing through list of values\n",
    "print (df.iloc[[1, 3, 5], [1, 3]])\n",
    "print (df.iloc[1:3, :])\n",
    "print (df.iloc[:,1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14) Python Pandas - Statistical Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percent_change\n",
    "Series, DatFrames and Panel, all have the function pct_change(). \n",
    "\n",
    "This function compares every element with its prior element and computes the change percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         NaN\n",
      "1    1.000000\n",
      "2    0.500000\n",
      "3    0.333333\n",
      "4    0.250000\n",
      "5   -0.200000\n",
      "dtype: float64\n",
      "          0         1\n",
      "0 -0.397833 -0.666450\n",
      "1  0.773928 -0.910957\n",
      "2  0.436384 -0.710265\n",
      "3  0.312070 -0.813244\n",
      "4  0.606927 -3.319317\n",
      "-----\n",
      "          0         1\n",
      "0       NaN       NaN\n",
      "1 -2.945361  0.366881\n",
      "2 -0.436144 -0.220309\n",
      "3 -0.284873  0.144986\n",
      "4  0.944841  3.081577\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1,2,3,4,5,4])\n",
    "print (s.pct_change())\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(5, 2))\n",
    "print (df)\n",
    "print ('-----')\n",
    "print (df.pct_change())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "Covariance is applied on series data. \n",
    "\n",
    "Covariance measures the directional relationship between the returns on two assets. A positive covariance means that asset returns move together while a negative covariance means they move inversely\n",
    "\n",
    "The Series object has a method cov to compute covariance between series objects. \n",
    "\n",
    "A will be excluded automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.582991\n",
      "1   -0.451424\n",
      "2   -0.896725\n",
      "3   -0.160549\n",
      "4   -1.394494\n",
      "5    0.285174\n",
      "6    0.369086\n",
      "7    0.600121\n",
      "8   -0.619606\n",
      "9    1.865283\n",
      "dtype: float64\n",
      "----\n",
      "0    1.570076\n",
      "1   -0.832181\n",
      "2   -0.275313\n",
      "3   -1.504630\n",
      "4    1.082287\n",
      "5    0.477978\n",
      "6    0.623116\n",
      "7   -2.366043\n",
      "8   -0.134520\n",
      "9    1.061337\n",
      "dtype: float64\n",
      "----\n",
      "1.5576966888571526\n",
      "----\n",
      "0.14277663105485358\n"
     ]
    }
   ],
   "source": [
    "s1 = pd.Series(np.random.randn(10))\n",
    "s2 = pd.Series(np.random.randn(10))\n",
    "print(s1)\n",
    "print('----')\n",
    "print(s2)\n",
    "print('----')\n",
    "print (s1.cov(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2943954018192288\n",
      "          a         b         c         d         e\n",
      "a  1.107693 -0.294395  0.459045  0.027648  0.606500\n",
      "b -0.294395  1.992142  0.384695  0.243970  0.041020\n",
      "c  0.459045  0.384695  1.017495 -0.358177  0.244832\n",
      "d  0.027648  0.243970 -0.358177  1.554691  0.048919\n",
      "e  0.606500  0.041020  0.244832  0.048919  0.629052\n"
     ]
    }
   ],
   "source": [
    "# Covariance method when applied on a DataFrame, computes cov between all the columns.\n",
    "frame = pd.DataFrame(np.random.randn(10, 5), columns=['a', 'b', 'c', 'd', 'e'])\n",
    "print (frame['a'].cov(frame['b']))\n",
    "print (frame.cov())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "Correlation shows the linear relationship between any two array of values (series). \n",
    "\n",
    "There are multiple methods to compute the correlation like pearson(default), spearman and kendall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a         b         c         d         e\n",
      "0  0.441678 -0.180913  1.223113 -1.091239 -0.149920\n",
      "1  0.382027  0.836875 -1.696920  0.123200  0.425069\n",
      "2 -0.108084  0.539072 -1.046926 -0.600511  0.450598\n",
      "3 -1.106332  0.148094  0.631345 -0.282965  0.599713\n",
      "4 -2.407169  0.428396 -0.948960  0.909304 -0.941714\n",
      "5 -0.990910 -1.213830 -0.448957  1.009545  0.836346\n",
      "6 -1.783301 -0.754662  0.678181  0.401389  2.842763\n",
      "7  0.482467  1.110647 -0.687452  1.090277 -0.301668\n",
      "8 -0.853196 -0.767867  1.100886  0.563283  1.439694\n",
      "9 -0.236303 -1.308712  1.067584 -0.285621 -1.112487\n",
      "-----------\n",
      "0.30351441529829754\n",
      "-----------\n",
      "          a         b         c         d         e\n",
      "a  1.000000  0.303514 -0.082003 -0.414772 -0.274815\n",
      "b  0.303514  1.000000 -0.665677  0.028298 -0.261798\n",
      "c -0.082003 -0.665677  1.000000 -0.359364  0.188506\n",
      "d -0.414772  0.028298 -0.359364  1.000000  0.123479\n",
      "e -0.274815 -0.261798  0.188506  0.123479  1.000000\n"
     ]
    }
   ],
   "source": [
    "frame = pd.DataFrame(np.random.randn(10, 5), columns=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "print(frame)\n",
    "print('-----------')\n",
    "print (frame['a'].corr(frame['b']))\n",
    "print('-----------')\n",
    "print (frame.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ranking\n",
    "Data Ranking produces ranking for each element in the array of elements. In case of ties, assigns the mean rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0.664107\n",
      "b    0.322982\n",
      "c    0.467965\n",
      "d    0.001192\n",
      "e   -0.927700\n",
      "dtype: float64\n",
      "-----\n",
      "a    0.664107\n",
      "b    0.322982\n",
      "c    0.467965\n",
      "d    0.322982\n",
      "e   -0.927700\n",
      "dtype: float64\n",
      "-----\n",
      "a    5.0\n",
      "b    2.5\n",
      "c    4.0\n",
      "d    2.5\n",
      "e    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(np.random.randn(5), index=list('abcde'))\n",
    "print(s)\n",
    "print('-----')\n",
    "s['d'] = s['b'] # so there's a tie\n",
    "print(s)\n",
    "print('-----')\n",
    "print (s.rank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank optionally takes a parameter ascending which by default is true; when false, data is reverse-ranked, with larger values assigned a smaller rank.\n",
    "\n",
    "Rank supports different tie-breaking methods, specified with the method parameter −\n",
    "\n",
    "- average − average rank of tied group\n",
    "\n",
    "- min − lowest rank in the group\n",
    "\n",
    "- max − highest rank in the group\n",
    "\n",
    "- first − ranks assigned in the order they appear in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15) Python Pandas - Window Functions\n",
    "\n",
    "Pandas provide few variants like rolling, expanding and exponentially moving weights for window statistics. \n",
    "\n",
    "Among these are sum, mean, median, variance, covariance, correlation, etc.\n",
    "\n",
    "We will now learn how each of these can be applied on DataFrame objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .rolling() Function\n",
    "This function can be applied on a series of data. \n",
    "\n",
    "Specify the window=n argument and apply the appropriate statistical function on top of it.\n",
    "\n",
    "Since the window size is 3, for first two elements there are nulls and from third the value will be the average of the n, n-1 and n-2 elements. \n",
    "\n",
    "Thus we can also apply various functions as mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01 -1.355406  0.969797 -0.092458 -0.142542\n",
      "2000-01-02 -1.624228  0.707305 -0.504949  0.549216\n",
      "2000-01-03  0.227567 -0.503743  0.344898 -1.740634\n",
      "2000-01-04  0.243121  0.619472  0.882900  0.111458\n",
      "2000-01-05  0.524945 -0.816169 -0.867034 -1.298130\n",
      "2000-01-06  0.717560 -0.019823 -0.155710 -0.084693\n",
      "2000-01-07 -0.023133 -1.143906  0.584284  0.932773\n",
      "2000-01-08 -1.939812 -0.195755  0.390462  0.027241\n",
      "2000-01-09 -0.395822 -0.139632 -0.776015 -0.523471\n",
      "2000-01-10  0.386922  0.717159 -0.428217 -0.851800\n",
      "------------\n",
      "                   A         B         C         D\n",
      "2000-01-01       NaN       NaN       NaN       NaN\n",
      "2000-01-02       NaN       NaN       NaN       NaN\n",
      "2000-01-03 -0.917356  0.391120 -0.084170 -0.444653\n",
      "2000-01-04 -0.384514  0.274345  0.240950 -0.359987\n",
      "2000-01-05  0.331878 -0.233480  0.120255 -0.975769\n",
      "2000-01-06  0.495209 -0.072173 -0.046615 -0.423788\n",
      "2000-01-07  0.406458 -0.659966 -0.146153 -0.150017\n",
      "2000-01-08 -0.415128 -0.453162  0.273012  0.291774\n",
      "2000-01-09 -0.786256 -0.493098  0.066244  0.145514\n",
      "2000-01-10 -0.649571  0.127257 -0.271257 -0.449343\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=10),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "print(df)\n",
    "print('------------')\n",
    "print (df.rolling(window=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .expanding() Function\n",
    "This function can be applied on a series of data. \n",
    "\n",
    "Specify the min_periods=n argument and apply the appropriate statistical function on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01 -1.788799  0.122977  1.374484 -0.582391\n",
      "2000-01-02  0.883520  1.180158  1.744566 -0.905274\n",
      "2000-01-03  1.304840  1.063514 -0.181567 -0.819334\n",
      "2000-01-04  1.584311  0.195699  0.624326 -0.722926\n",
      "2000-01-05  0.270695  0.812317  0.120551 -1.017247\n",
      "2000-01-06  0.213272  2.241546 -1.670690  0.250066\n",
      "2000-01-07 -0.208292  0.124864 -1.417460 -1.032906\n",
      "2000-01-08 -0.403341 -0.012454  0.697716 -1.379395\n",
      "2000-01-09  0.162550  0.623233 -0.665754  0.779444\n",
      "2000-01-10 -0.704732 -0.324605  0.735579 -0.279799\n",
      "------------\n",
      "                   A         B         C         D\n",
      "2000-01-01       NaN       NaN       NaN       NaN\n",
      "2000-01-02       NaN       NaN       NaN       NaN\n",
      "2000-01-03  0.133187  0.788883  0.979161 -0.769000\n",
      "2000-01-04  0.495968  0.640587  0.890452 -0.757481\n",
      "2000-01-05  0.450914  0.674933  0.736472 -0.809434\n",
      "2000-01-06  0.411307  0.936035  0.335278 -0.632851\n",
      "2000-01-07  0.322793  0.820154  0.084887 -0.690002\n",
      "2000-01-08  0.232026  0.716078  0.161491 -0.776176\n",
      "2000-01-09  0.224306  0.705762  0.069575 -0.603329\n",
      "2000-01-10  0.131402  0.602725  0.136175 -0.570976\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=10),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "print(df)\n",
    "print('------------')\n",
    "print (df.expanding(min_periods=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .ewm() Function\n",
    "ewm is applied on a series of data. \n",
    "\n",
    "Specify any of the com, span, halflife argument and apply the appropriate statistical function on top of it. \n",
    "\n",
    "It assigns the weights exponentially.\n",
    "\n",
    "Window functions are majorly used in finding the trends within the data graphically by smoothing the curve. \n",
    "\n",
    "If there is lot of variation in the everyday data and a lot of data points are available, then taking the samples and plotting is one method and applying the window computations and plotting the graph on the results is another method. \n",
    "\n",
    "By these methods, we can smooth the curve or the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01 -0.588514 -0.868976 -0.645838  1.527310\n",
      "2000-01-02  0.828657  0.814584  1.304299 -0.490318\n",
      "2000-01-03  0.149349 -0.759152 -1.448494 -1.069553\n",
      "2000-01-04 -1.687603  0.629991 -0.156174  0.818893\n",
      "2000-01-05 -0.159162  1.727522 -1.657568 -1.353714\n",
      "2000-01-06  0.985551 -0.735970 -0.474191 -0.740767\n",
      "2000-01-07 -0.762062 -1.018285 -0.239939 -0.157420\n",
      "2000-01-08 -1.986198 -1.506184  1.237622 -0.731850\n",
      "2000-01-09  0.053202 -0.163322  0.697033 -0.464737\n",
      "2000-01-10  0.503914 -1.662618  1.209446  0.180170\n",
      "------------\n",
      "                   A         B         C         D\n",
      "2000-01-01 -0.588514 -0.868976 -0.645838  1.527310\n",
      "2000-01-02  0.474364  0.393694  0.816765  0.014089\n",
      "2000-01-03  0.249354 -0.404430 -0.751491 -0.736124\n",
      "2000-01-04 -1.058092  0.293804 -0.349652  0.313512\n",
      "2000-01-05 -0.456329  1.253565 -1.225199 -0.802565\n",
      "2000-01-06  0.506245 -0.074614 -0.723839 -0.761309\n",
      "2000-01-07 -0.339680 -0.704016 -0.401092 -0.358532\n",
      "2000-01-08 -1.437526 -1.238876  0.691551 -0.607448\n",
      "2000-01-09 -0.443657 -0.521803  0.695206 -0.512303\n",
      "2000-01-10  0.188068 -1.282360  1.038038 -0.050647\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=10),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print(df)\n",
    "print('------------')\n",
    "print (df.ewm(com=0.5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16) Python Pandas - Aggregations\n",
    "\n",
    "Once the rolling, expanding and ewm objects are created, several methods are available to perform aggregations on data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Aggregations on DataFrame\n",
    "Let us create a DataFrame and apply aggregations on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01  2.093084  0.650056 -0.504334 -1.112836\n",
      "2000-01-02  0.645768 -0.696436  0.025225 -0.670260\n",
      "2000-01-03 -0.319474  1.536701  0.478683  0.914832\n",
      "2000-01-04 -1.356875  0.158510 -0.830118 -2.499415\n",
      "2000-01-05  1.058257 -1.050805  0.462871  0.024862\n",
      "2000-01-06  0.862037  0.127469  1.170546 -0.222535\n",
      "2000-01-07  1.168986  1.075133  0.365091 -1.516365\n",
      "2000-01-08 -0.528051  0.465073 -2.016672 -0.731254\n",
      "2000-01-09  0.476977  0.410543  0.179917  1.654979\n",
      "2000-01-10 -0.578692 -2.942543 -0.736697  0.514925\n",
      "------\n",
      "Rolling [window=3,min_periods=1,center=False,axis=0]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=10),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print (df)\n",
    "print('------')\n",
    "r = df.rolling(window=3,min_periods=1)\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can aggregate by passing a function to the entire DataFrame, or select a column via the standard get item method.\n",
    "\n",
    "## Apply Aggregation on a Whole Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01  0.354936 -0.102494 -2.154018 -0.413744\n",
      "2000-01-02  0.894142 -0.125872 -0.719151 -1.698485\n",
      "2000-01-03 -1.219417 -0.323212  0.377948 -0.389320\n",
      "2000-01-04  0.938292  0.999271  0.254070 -0.775000\n",
      "2000-01-05  0.646395  0.438859  0.517734  0.304511\n",
      "2000-01-06  1.443373 -0.472571 -1.499498  0.665961\n",
      "2000-01-07  0.978223 -1.210058  0.643449 -0.729435\n",
      "2000-01-08 -0.659633 -0.901293  0.390263 -0.210567\n",
      "2000-01-09  2.895695  0.116966 -1.021631  0.105244\n",
      "2000-01-10  0.560988  0.216605 -2.804008 -1.659948\n",
      "------\n",
      "                   A         B         C         D\n",
      "2000-01-01  0.354936 -0.102494 -2.154018 -0.413744\n",
      "2000-01-02  1.249079 -0.228366 -2.873169 -2.112228\n",
      "2000-01-03  0.029662 -0.551578 -2.495220 -2.501549\n",
      "2000-01-04  0.613018  0.550188 -0.087133 -2.862805\n",
      "2000-01-05  0.365270  1.114918  1.149753 -0.859810\n",
      "2000-01-06  3.028060  0.965560 -0.727694  0.195471\n",
      "2000-01-07  3.067991 -1.243770 -0.338315  0.241036\n",
      "2000-01-08  1.761963 -2.583922 -0.465786 -0.274041\n",
      "2000-01-09  3.214285 -1.994385  0.012081 -0.834758\n",
      "2000-01-10  2.797050 -0.567722 -3.435377 -1.765270\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=10),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print (df)\n",
    "print('------')\n",
    "r = df.rolling(window=3,min_periods=1)\n",
    "print (r.aggregate(np.sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Aggregation on a Single Column of a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01 -1.281795 -1.480539  0.552854  1.082288\n",
      "2000-01-02  1.370825  0.631940  0.348050  0.897265\n",
      "2000-01-03  0.948595 -1.441848 -0.706854 -0.228789\n",
      "2000-01-04  0.585888  0.515916  0.452768 -0.906791\n",
      "2000-01-05 -1.709108 -1.110694  1.417523  0.013303\n",
      "2000-01-06  0.924583  0.526121 -1.439100  1.476905\n",
      "2000-01-07 -0.462436 -0.935844 -0.903982 -1.486836\n",
      "2000-01-08 -0.089715 -1.318669  0.445494  0.820520\n",
      "2000-01-09  1.255038  0.106238  0.158039  0.679045\n",
      "2000-01-10 -0.408477 -1.251715 -0.629454 -0.046438\n",
      "--------\n",
      "2000-01-01   -1.281795\n",
      "2000-01-02    0.089030\n",
      "2000-01-03    1.037625\n",
      "2000-01-04    2.905308\n",
      "2000-01-05   -0.174625\n",
      "2000-01-06   -0.198636\n",
      "2000-01-07   -1.246960\n",
      "2000-01-08    0.372432\n",
      "2000-01-09    0.702887\n",
      "2000-01-10    0.756845\n",
      "Freq: D, Name: A, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=10),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print (df)\n",
    "print('--------')\n",
    "r = df.rolling(window=3,min_periods=1)\n",
    "print (r['A'].aggregate(np.sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Aggregation on Multiple Columns of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01  1.549723 -0.259055 -0.949065 -0.356619\n",
      "2000-01-02  1.173574  1.428391  0.513213 -1.756689\n",
      "2000-01-03 -0.308266 -0.460753 -0.892924  0.568122\n",
      "2000-01-04 -0.893599  0.057230 -1.364423 -0.584923\n",
      "2000-01-05 -1.798258 -0.655925 -1.905614 -1.270296\n",
      "2000-01-06 -1.536146  1.437252  0.778125  0.510253\n",
      "2000-01-07 -0.920759 -0.311227 -1.652505  0.319493\n",
      "2000-01-08 -0.569061  0.009078 -0.667197 -1.474495\n",
      "2000-01-09 -0.032741 -0.095448 -0.428715  0.495496\n",
      "2000-01-10  1.253885  0.749009  2.121935 -1.868863\n",
      "----------\n",
      "                   A         B\n",
      "2000-01-01  1.549723 -0.259055\n",
      "2000-01-02  2.723298  1.169337\n",
      "2000-01-03  2.415031  0.708584\n",
      "2000-01-04 -0.028291  1.024869\n",
      "2000-01-05 -3.000124 -1.059448\n",
      "2000-01-06 -4.228003  0.838557\n",
      "2000-01-07 -4.255162  0.470100\n",
      "2000-01-08 -3.025966  1.135103\n",
      "2000-01-09 -1.522561 -0.397597\n",
      "2000-01-10  0.652082  0.662639\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=10),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print (df)\n",
    "print('----------')\n",
    "r = df.rolling(window=3,min_periods=1)\n",
    "print (r[['A','B']].aggregate(np.sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Multiple Functions on a Single Column of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01  0.119215 -1.175641 -1.395739  0.231074\n",
      "2000-01-02  1.406545 -0.423840  0.750759  0.279515\n",
      "2000-01-03  0.515560  1.848297 -2.166943  0.685413\n",
      "2000-01-04 -0.165913  1.152795 -0.995585  1.132788\n",
      "2000-01-05  1.565688 -0.297525 -0.267107  0.116237\n",
      "2000-01-06  0.456168 -0.078110  0.003799 -1.173854\n",
      "2000-01-07 -1.332433  1.620274 -0.802072  1.209821\n",
      "2000-01-08  0.154867 -0.595071 -1.030937 -0.224319\n",
      "2000-01-09 -0.155898  0.744708  1.075321  0.019986\n",
      "2000-01-10 -0.419343 -0.261092  1.389446 -2.066941\n",
      "------\n",
      "                 sum      mean\n",
      "2000-01-01  0.119215  0.119215\n",
      "2000-01-02  1.525760  0.762880\n",
      "2000-01-03  2.041320  0.680440\n",
      "2000-01-04  1.756193  0.585398\n",
      "2000-01-05  1.915335  0.638445\n",
      "2000-01-06  1.855943  0.618648\n",
      "2000-01-07  0.689423  0.229808\n",
      "2000-01-08 -0.721398 -0.240466\n",
      "2000-01-09 -1.333465 -0.444488\n",
      "2000-01-10 -0.420374 -0.140125\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=10),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print (df)\n",
    "print('------')\n",
    "r = df.rolling(window=3,min_periods=1)\n",
    "print (r['A'].aggregate([np.sum,np.mean]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Multiple Functions on Multiple Columns of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01  0.649054 -0.115639  1.152082  0.415603\n",
      "2000-01-02  0.677069  1.615485  0.109536 -0.657105\n",
      "2000-01-03 -0.670904  0.158960 -1.459623 -1.321065\n",
      "2000-01-04 -0.993384  0.456426 -0.235304  0.346353\n",
      "2000-01-05  0.467660 -2.569621  1.183904  1.152986\n",
      "2000-01-06  1.637219  1.320414 -0.556544  0.455153\n",
      "2000-01-07  0.153414  0.775801 -1.319891  0.154426\n",
      "2000-01-08 -0.332921  0.319636 -0.566834 -2.109508\n",
      "2000-01-09 -0.295427 -0.524007 -0.229611 -0.165649\n",
      "2000-01-10  0.193247 -0.819361  1.902243  0.251754\n",
      "------\n",
      "                   A                   B          \n",
      "                 sum      mean       sum      mean\n",
      "2000-01-01  0.649054  0.649054 -0.115639 -0.115639\n",
      "2000-01-02  1.326123  0.663062  1.499846  0.749923\n",
      "2000-01-03  0.655219  0.218406  1.658806  0.552935\n",
      "2000-01-04 -0.987219 -0.329073  2.230872  0.743624\n",
      "2000-01-05 -1.196629 -0.398876 -1.954234 -0.651411\n",
      "2000-01-06  1.111494  0.370498 -0.792781 -0.264260\n",
      "2000-01-07  2.258293  0.752764 -0.473407 -0.157802\n",
      "2000-01-08  1.457712  0.485904  2.415851  0.805284\n",
      "2000-01-09 -0.474934 -0.158311  0.571430  0.190477\n",
      "2000-01-10 -0.435101 -0.145034 -1.023732 -0.341244\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=10),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print (df)\n",
    "print('------')\n",
    "r = df.rolling(window=3,min_periods=1)\n",
    "print (r[['A','B']].aggregate([np.sum,np.mean]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Different Functions to Different Columns of a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2000-01-01  1.039365  0.181513  1.229984  0.355142\n",
      "2000-01-02 -1.610152 -0.965870  1.922440 -0.491289\n",
      "2000-01-03  0.392054  1.616966  1.165091 -0.905374\n",
      "------\n",
      "                   A         B\n",
      "2000-01-01  1.039365  0.181513\n",
      "2000-01-02 -0.570786 -0.392178\n",
      "2000-01-03 -0.178732  0.277537\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(3, 4),\n",
    "   index = pd.date_range('1/1/2000', periods=3),\n",
    "   columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "print(df)\n",
    "print('------')\n",
    "r = df.rolling(window=3,min_periods=1)\n",
    "print(r.aggregate({'A' : np.sum,'B' : np.mean}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17) Python Pandas - Missing Data\n",
    "\n",
    "Missing data is always a problem in real life scenarios. \n",
    "\n",
    "Areas like machine learning and data mining face severe issues in the accuracy of their model predictions because of poor quality of data caused by missing values. \n",
    "\n",
    "In these areas, missing value treatment is a major point of focus to make their models more accurate and valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -0.257515  3.059025 -0.513315\n",
      "b       NaN       NaN       NaN\n",
      "c  0.058466 -0.278135 -1.467531\n",
      "d       NaN       NaN       NaN\n",
      "e -1.095764 -0.192962 -0.693076\n",
      "f  0.360707 -0.862886  0.623427\n",
      "g       NaN       NaN       NaN\n",
      "h -1.854477  0.705064  0.480665\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f','h'],columns=['one', 'two', 'three'])\n",
    "\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Missing Values\n",
    "To make detecting missing values easier (and across different array dtypes), \n",
    "\n",
    "Pandas provides the isnull() and notnull() functions, which are also methods on Series and DataFrame objects −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    False\n",
      "b     True\n",
      "c    False\n",
      "d     True\n",
      "e    False\n",
      "f    False\n",
      "g     True\n",
      "h    False\n",
      "Name: one, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f','h'],columns=['one', 'two', 'three'])\n",
    "\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "\n",
    "print (df['one'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     True\n",
      "b    False\n",
      "c     True\n",
      "d    False\n",
      "e     True\n",
      "f     True\n",
      "g    False\n",
      "h     True\n",
      "Name: one, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f','h'],columns=['one', 'two', 'three'])\n",
    "\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "\n",
    "print (df['one'].notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations with Missing Data\n",
    "\n",
    "When summing data, NA will be treated as Zero\n",
    "\n",
    "If the data are all NA, then the result will be NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3892925040718338\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f','h'],columns=['one', 'two', 'three'])\n",
    "\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "\n",
    "print (df['one'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(index=[0,1,2,3,4,5],columns=['one','two'])\n",
    "print (df['one'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning / Filling Missing Data\n",
    "Pandas provides various methods for cleaning the missing values. The fillna function can “fill in” NA values with non-null data in a couple of ways, which we have illustrated in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace NaN with a Scalar Value\n",
    "The following program shows how you can replace \"NaN\" with \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a  0.033392 -0.704642  0.038243\n",
      "b       NaN       NaN       NaN\n",
      "c -0.668708 -1.837438 -0.207615\n",
      "NaN replaced with '0':\n",
      "        one       two     three\n",
      "a  0.033392 -0.704642  0.038243\n",
      "b  0.000000  0.000000  0.000000\n",
      "c -0.668708 -1.837438 -0.207615\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(3, 3), index=['a', 'c', 'e'],columns=['one','two', 'three'])\n",
    "\n",
    "df = df.reindex(['a', 'b', 'c'])\n",
    "\n",
    "print (df)\n",
    "print (\"NaN replaced with '0':\")\n",
    "print (df.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NA Forward and Backward\n",
    "Using the concepts of filling discussed in the ReIndexing Chapter we will fill the missing values.\n",
    "\n",
    "|Sr.No\t|Method & Action|\n",
    "|-|-|\n",
    "|1\t|pad/fill <br> Fill methods Forward|\n",
    "|2\t|bfill/backfill <br>Fill methods Backward|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -1.051505 -0.947813 -1.361278\n",
      "b -1.051505 -0.947813 -1.361278\n",
      "c  1.231296 -0.130872 -0.885178\n",
      "d  1.231296 -0.130872 -0.885178\n",
      "e -0.963283 -0.994920 -0.843728\n",
      "f -0.987930 -2.069104  1.179432\n",
      "g -0.987930 -2.069104  1.179432\n",
      "h -0.434235 -1.229606 -0.115774\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f','h'],columns=['one', 'two', 'three'])\n",
    "\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "\n",
    "print (df.fillna(method='pad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -0.374283 -0.406474 -0.003246\n",
      "b -3.447744 -1.705291 -0.052140\n",
      "c -3.447744 -1.705291 -0.052140\n",
      "d  0.974502  0.009645  0.227220\n",
      "e  0.974502  0.009645  0.227220\n",
      "f  1.877391  1.305844 -0.611206\n",
      "g -1.071785  0.069925 -2.235651\n",
      "h -1.071785  0.069925 -2.235651\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f','h'],columns=['one', 'two', 'three'])\n",
    "\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "\n",
    "print(df.fillna(method='backfill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Missing Values\n",
    "If you want to simply exclude the missing values, then use the dropna function along with the axis argument. \n",
    "\n",
    "By default, axis=0, i.e., along row, which means that if any value within a row is NA then the whole row is excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a  0.331696  2.313748 -1.456531\n",
      "c  0.729750  1.086801 -1.496598\n",
      "e -0.532308 -0.241517 -0.200317\n",
      "f  1.139250  0.769868  2.205306\n",
      "h -1.230757  0.137145  0.709181\n",
      "-------\n",
      "        one       two     three\n",
      "a  0.331696  2.313748 -1.456531\n",
      "c  0.729750  1.086801 -1.496598\n",
      "e -0.532308 -0.241517 -0.200317\n",
      "f  1.139250  0.769868  2.205306\n",
      "h -1.230757  0.137145  0.709181\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f','h'],columns=['one', 'two', 'three'])\n",
    "print (df)\n",
    "print('-------')\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "print (df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -1.305326  0.904209 -1.137406\n",
      "c  0.919570 -1.033392 -0.776335\n",
      "e -0.008856 -0.676585  0.288061\n",
      "f  0.746275 -1.014291  1.150162\n",
      "h  0.502426  0.707054  0.507842\n",
      "-------\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [a, b, c, d, e, f, g, h]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f','h'],columns=['one', 'two', 'three'])\n",
    "print (df)\n",
    "print('-------')\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "print (df.dropna(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Missing (or) Generic Values\n",
    "Many times, we have to replace a generic value with some specific value. \n",
    "\n",
    "We can achieve this by applying the replace method.\n",
    "\n",
    "Replacing NA with a scalar value is equivalent behavior of the fillna() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    one   two\n",
      "0    10  1000\n",
      "1    20     0\n",
      "2    30    30\n",
      "3    40    40\n",
      "4    50    50\n",
      "5  2000    60\n",
      "-------\n",
      "   one  two\n",
      "0   10   10\n",
      "1   20    0\n",
      "2   30   30\n",
      "3   40   40\n",
      "4   50   50\n",
      "5   60   60\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'one':[10,20,30,40,50,2000], 'two':[1000,0,30,40,50,60]})\n",
    "print (df)\n",
    "print('-------')\n",
    "print (df.replace({1000:10,2000:60}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18) Python Pandas - GroupBy\n",
    "\n",
    "Any groupby operation involves one of the following operations on the original object. They are −\n",
    "\n",
    "- Splitting the Object\n",
    "- Applying a function\n",
    "- Combining the results\n",
    "\n",
    "In many situations, we split the data into sets and we apply some functionality on each subset. In the apply functionality, we can perform the following operations −\n",
    "\n",
    "- Aggregation − computing a summary statistic\n",
    "- Transformation − perform some group-specific operation\n",
    "- Filtration − discarding the data with some condition\n",
    "\n",
    "Let us now create a DataFrame object and perform all the operations on it −"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Groups\n",
    "Pandas object can be split into any of their objects. There are multiple ways to split an object like −\n",
    "\n",
    "- obj.groupby('key')\n",
    "- obj.groupby(['key1','key2'])\n",
    "- obj.groupby(key,axis=1)\n",
    "\n",
    "Let us now see how the grouping objects can be applied to the DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Devils': Int64Index([2, 3], dtype='int64'), 'Kings': Int64Index([4, 6, 7], dtype='int64'), 'Riders': Int64Index([0, 1, 8, 11], dtype='int64'), 'Royals': Int64Index([9, 10], dtype='int64'), 'kings': Int64Index([5], dtype='int64')}\n"
     ]
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "\n",
    "print (df.groupby('Team').groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Devils', 2014): Int64Index([2], dtype='int64'), ('Devils', 2015): Int64Index([3], dtype='int64'), ('Kings', 2014): Int64Index([4], dtype='int64'), ('Kings', 2016): Int64Index([6], dtype='int64'), ('Kings', 2017): Int64Index([7], dtype='int64'), ('Riders', 2014): Int64Index([0], dtype='int64'), ('Riders', 2015): Int64Index([1], dtype='int64'), ('Riders', 2016): Int64Index([8], dtype='int64'), ('Riders', 2017): Int64Index([11], dtype='int64'), ('Royals', 2014): Int64Index([9], dtype='int64'), ('Royals', 2015): Int64Index([10], dtype='int64'), ('kings', 2015): Int64Index([5], dtype='int64')}\n"
     ]
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "print (df.groupby(['Team','Year']).groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through Groups\n",
    "With the groupby object in hand, we can iterate through the object similar to itertools.obj.\n",
    "\n",
    "By default, the groupby object has the same label name as the group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2014: Int64Index([0, 2, 4, 9], dtype='int64'), 2015: Int64Index([1, 3, 5, 10], dtype='int64'), 2016: Int64Index([6, 8], dtype='int64'), 2017: Int64Index([7, 11], dtype='int64')}\n",
      "-----\n",
      "2014\n",
      "     Team  Rank  Year  Points\n",
      "0  Riders     1  2014     876\n",
      "2  Devils     2  2014     863\n",
      "4   Kings     3  2014     741\n",
      "9  Royals     4  2014     701\n",
      "2015\n",
      "      Team  Rank  Year  Points\n",
      "1   Riders     2  2015     789\n",
      "3   Devils     3  2015     673\n",
      "5    kings     4  2015     812\n",
      "10  Royals     1  2015     804\n",
      "2016\n",
      "     Team  Rank  Year  Points\n",
      "6   Kings     1  2016     756\n",
      "8  Riders     2  2016     694\n",
      "2017\n",
      "      Team  Rank  Year  Points\n",
      "7    Kings     1  2017     788\n",
      "11  Riders     2  2017     690\n"
     ]
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "\n",
    "grouped = df.groupby('Year')\n",
    "\n",
    "print(grouped.groups)\n",
    "print('-----')\n",
    "\n",
    "for name,group in grouped:\n",
    "   print (name)\n",
    "   print (group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a Group\n",
    "Using the get_group() method, we can select a single group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Team  Rank  Year  Points\n",
      "0  Riders     1  2014     876\n",
      "2  Devils     2  2014     863\n",
      "4   Kings     3  2014     741\n",
      "9  Royals     4  2014     701\n"
     ]
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "\n",
    "grouped = df.groupby('Year')\n",
    "print (grouped.get_group(2014))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations\n",
    "An aggregated function returns a single aggregated value for each group. \n",
    "\n",
    "Once the group by object is created, several aggregation operations can be performed on the grouped data.\n",
    "\n",
    "An obvious one is aggregation via the aggregate or equivalent agg method −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2014    795.25\n",
      "2015    769.50\n",
      "2016    725.00\n",
      "2017    739.00\n",
      "Name: Points, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "\n",
    "grouped = df.groupby('Year')\n",
    "print (grouped['Points'].agg(np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rank  Year  Points\n",
      "Team                      \n",
      "Devils     2     2       2\n",
      "Kings      3     3       3\n",
      "Riders     4     4       4\n",
      "Royals     2     2       2\n",
      "kings      1     1       1\n"
     ]
    }
   ],
   "source": [
    "# Another way to see the size of each group is by applying the size() function −\n",
    "\n",
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "\n",
    "# Attribute Access in Python Pandas\n",
    "grouped = df.groupby('Team')\n",
    "print (grouped.agg(np.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Multiple Aggregation Functions at Once\n",
    "With grouped Series, you can also pass a list or dict of functions to do aggregation with, and generate DataFrame as output −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sum        mean         std\n",
      "Team                                \n",
      "Devils  1536  768.000000  134.350288\n",
      "Kings   2285  761.666667   24.006943\n",
      "Riders  3049  762.250000   88.567771\n",
      "Royals  1505  752.500000   72.831998\n",
      "kings    812  812.000000         NaN\n"
     ]
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "\n",
    "grouped = df.groupby('Team')\n",
    "print (grouped['Points'].agg([np.sum, np.mean, np.std]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "Transformation on a group or a column returns an object that is indexed the same size of that is being grouped. \n",
    "\n",
    "Thus, the transform should return a result that is the same size as that of a group chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Rank       Year     Points\n",
      "0  -15.000000 -11.618950  12.843272\n",
      "1    5.000000  -3.872983   3.020286\n",
      "2   -7.071068  -7.071068   7.071068\n",
      "3    7.071068   7.071068  -7.071068\n",
      "4   11.547005 -10.910895  -8.608621\n",
      "5         NaN        NaN        NaN\n",
      "6   -5.773503   2.182179  -2.360428\n",
      "7   -5.773503   8.728716  10.969049\n",
      "8    5.000000   3.872983  -7.705963\n",
      "9    7.071068  -7.071068  -7.071068\n",
      "10  -7.071068   7.071068   7.071068\n",
      "11   5.000000  11.618950  -8.157595\n"
     ]
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "\n",
    "grouped = df.groupby('Team')\n",
    "score = lambda x: (x - x.mean()) / x.std()*10\n",
    "print (grouped.transform(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtration\n",
    "Filtration filters the data on a defined criteria and returns the subset of data. \n",
    "\n",
    "The filter() function is used to filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Team  Rank  Year  Points\n",
      "0   Riders     1  2014     876\n",
      "1   Riders     2  2015     789\n",
      "4    Kings     3  2014     741\n",
      "6    Kings     1  2016     756\n",
      "7    Kings     1  2017     788\n",
      "8   Riders     2  2016     694\n",
      "11  Riders     2  2017     690\n"
     ]
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "\n",
    "print (df.groupby('Team').filter(lambda x: len(x) >= 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above filter condition, we are asking to return the teams which have participated three or more times in IPL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19) Python Pandas - Merging/Joining\n",
    "\n",
    "Pandas has full-featured, high performance in-memory join operations idiomatically very similar to relational databases like SQL.\n",
    "\n",
    "Pandas provides a single function, merge, as the entry point for all standard database join operations between DataFrame objects −"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have used the following parameters −\n",
    "\n",
    "- left − A DataFrame object.\n",
    "\n",
    "- right − Another DataFrame object.\n",
    "\n",
    "- on − Columns (names) to join on. Must be found in both the left and right DataFrame objects.\n",
    "\n",
    "- left_on − Columns from the left DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n",
    "\n",
    "- right_on − Columns from the right DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n",
    "\n",
    "- left_index − If True, use the index (row labels) from the left DataFrame as its join key(s). In case of a DataFrame with a MultiIndex (hierarchical), the number of levels must match the number of join keys from the right DataFrame.\n",
    "\n",
    "- right_index − Same usage as left_index for the right DataFrame.\n",
    "\n",
    "- how − One of 'left', 'right', 'outer', 'inner'. Defaults to inner. Each method has been described below.\n",
    "\n",
    "- sort − Sort the result DataFrame by the join keys in lexicographical order. Defaults to True, setting to False will improve the performance substantially in many cases.\n",
    "\n",
    "Let us now create two different DataFrames and perform the merging operations on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    Name subject_id\n",
      "0   1    Alex       sub1\n",
      "1   2     Amy       sub2\n",
      "2   3   Allen       sub4\n",
      "3   4   Alice       sub6\n",
      "4   5  Ayoung       sub5\n",
      "   id   Name subject_id\n",
      "0   1  Billy       sub2\n",
      "1   2  Brian       sub4\n",
      "2   3   Bran       sub3\n",
      "3   4  Bryce       sub6\n",
      "4   5  Betty       sub5\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "left = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
    "   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n",
    "right = pd.DataFrame(\n",
    "   {'id':[1,2,3,4,5],\n",
    "   'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
    "   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n",
    "print (left)\n",
    "print (right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  Name_x subject_id_x Name_y subject_id_y\n",
      "0   1    Alex         sub1  Billy         sub2\n",
      "1   2     Amy         sub2  Brian         sub4\n",
      "2   3   Allen         sub4   Bran         sub3\n",
      "3   4   Alice         sub6  Bryce         sub6\n",
      "4   5  Ayoung         sub5  Betty         sub5\n"
     ]
    }
   ],
   "source": [
    "# Merge Two DataFrames on a Key\n",
    "\n",
    "left = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
    "   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n",
    "right = pd.DataFrame({\n",
    "\t'id':[1,2,3,4,5],\n",
    "   'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
    "   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n",
    "print (pd.merge(left,right,on='id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Using 'how' Argument\n",
    "\n",
    "The how argument to merge specifies how to determine which keys are to be included in the resulting table. \n",
    "\n",
    "If a key combination does not appear in either the left or the right tables, the values in the joined table will be NA.\n",
    "\n",
    "Here is a summary of the how options and their SQL equivalent names −\n",
    "\n",
    "|Merge Method\t|SQL Equivalent|Description|\n",
    "|-|-|-|\n",
    "|left|\tLEFT OUTER JOIN\t|Use keys from left object|\n",
    "|right|\tRIGHT OUTER JOIN\t|Use keys from right object|\n",
    "|outer|\tFULL OUTER JOIN\t|Use union of keys|\n",
    "|inner|\tINNER JOIN\t|Use intersection of keys|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    Name subject_id\n",
      "0   1    Alex       sub1\n",
      "1   2     Amy       sub2\n",
      "2   3   Allen       sub4\n",
      "3   4   Alice       sub6\n",
      "4   5  Ayoung       sub5\n",
      "---------\n",
      "   id   Name subject_id\n",
      "0   1  Billy       sub2\n",
      "1   2  Brian       sub4\n",
      "2   3   Bran       sub3\n",
      "3   4  Bryce       sub6\n",
      "4   5  Betty       sub5\n",
      "---------\n",
      "   id_x  Name_x subject_id  id_y Name_y\n",
      "0     1    Alex       sub1   NaN    NaN\n",
      "1     2     Amy       sub2   1.0  Billy\n",
      "2     3   Allen       sub4   2.0  Brian\n",
      "3     4   Alice       sub6   4.0  Bryce\n",
      "4     5  Ayoung       sub5   5.0  Betty\n"
     ]
    }
   ],
   "source": [
    "# Left Join\n",
    "left = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
    "   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n",
    "right = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
    "   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n",
    "print(left);\n",
    "print('---------')\n",
    "print(right);\n",
    "print('---------')\n",
    "print (pd.merge(left, right, on='subject_id', how='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    Name subject_id\n",
      "0   1    Alex       sub1\n",
      "1   2     Amy       sub2\n",
      "2   3   Allen       sub4\n",
      "3   4   Alice       sub6\n",
      "4   5  Ayoung       sub5\n",
      "---------\n",
      "   id   Name subject_id\n",
      "0   1  Billy       sub2\n",
      "1   2  Brian       sub4\n",
      "2   3   Bran       sub3\n",
      "3   4  Bryce       sub6\n",
      "4   5  Betty       sub5\n",
      "---------\n",
      "   id_x  Name_x subject_id  id_y Name_y\n",
      "0   2.0     Amy       sub2     1  Billy\n",
      "1   3.0   Allen       sub4     2  Brian\n",
      "2   4.0   Alice       sub6     4  Bryce\n",
      "3   5.0  Ayoung       sub5     5  Betty\n",
      "4   NaN     NaN       sub3     3   Bran\n"
     ]
    }
   ],
   "source": [
    "# Right Join\n",
    "left = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
    "   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n",
    "right = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
    "   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n",
    "print(left);\n",
    "print('---------')\n",
    "print(right);\n",
    "print('---------')\n",
    "print (pd.merge(left, right, on='subject_id', how='right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    Name subject_id\n",
      "0   1    Alex       sub1\n",
      "1   2     Amy       sub2\n",
      "2   3   Allen       sub4\n",
      "3   4   Alice       sub6\n",
      "4   5  Ayoung       sub5\n",
      "---------\n",
      "   id   Name subject_id\n",
      "0   1  Billy       sub2\n",
      "1   2  Brian       sub4\n",
      "2   3   Bran       sub3\n",
      "3   4  Bryce       sub6\n",
      "4   5  Betty       sub5\n",
      "---------\n",
      "   id_x  Name_x subject_id  id_y Name_y\n",
      "0   1.0    Alex       sub1   NaN    NaN\n",
      "1   2.0     Amy       sub2   1.0  Billy\n",
      "2   3.0   Allen       sub4   2.0  Brian\n",
      "3   4.0   Alice       sub6   4.0  Bryce\n",
      "4   5.0  Ayoung       sub5   5.0  Betty\n",
      "5   NaN     NaN       sub3   3.0   Bran\n"
     ]
    }
   ],
   "source": [
    "# Outer Join\n",
    "left = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
    "   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n",
    "right = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
    "   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n",
    "print(left);\n",
    "print('---------')\n",
    "print(right);\n",
    "print('---------')\n",
    "print (pd.merge(left, right, how='outer', on='subject_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    Name subject_id\n",
      "0   1    Alex       sub1\n",
      "1   2     Amy       sub2\n",
      "2   3   Allen       sub4\n",
      "3   4   Alice       sub6\n",
      "4   5  Ayoung       sub5\n",
      "---------\n",
      "   id   Name subject_id\n",
      "0   1  Billy       sub2\n",
      "1   2  Brian       sub4\n",
      "2   3   Bran       sub3\n",
      "3   4  Bryce       sub6\n",
      "4   5  Betty       sub5\n",
      "---------\n",
      "   id_x  Name_x subject_id  id_y Name_y\n",
      "0     2     Amy       sub2     1  Billy\n",
      "1     3   Allen       sub4     2  Brian\n",
      "2     4   Alice       sub6     4  Bryce\n",
      "3     5  Ayoung       sub5     5  Betty\n"
     ]
    }
   ],
   "source": [
    "# Inner Join\n",
    "# Joining will be performed on index. \n",
    "# Join operation honors the object on which it is called. \n",
    "# So, a.join(b) is not equal to b.join(a).\n",
    "\n",
    "left = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
    "   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n",
    "right = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
    "   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n",
    "print(left);\n",
    "print('---------')\n",
    "print(right);\n",
    "print('---------')\n",
    "print(pd.merge(left, right, on='subject_id', how='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20) Python Pandas - Concatenation\n",
    "Pandas provides various facilities for easily combining together Series, DataFrame, and Panel objects.\n",
    "\n",
    "objs − This is a sequence or mapping of Series, DataFrame, or Panel objects.\n",
    "\n",
    "axis − {0, 1, ...}, default 0. This is the axis to concatenate along.\n",
    "\n",
    "join − {‘inner’, ‘outer’}, default ‘outer’. How to handle indexes on other axis(es). Outer for union and inner for intersection.\n",
    "\n",
    "ignore_index − boolean, default False. If True, do not use the index values on the concatenation axis. The resulting axis will be labeled 0, ..., n - 1.\n",
    "\n",
    "join_axes − This is the list of Index objects. Specific indexes to use for the other (n-1) axes instead of performing inner/outer set logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating Objects\n",
    "The concat function does all of the heavy lifting of performing concatenation operations along an axis. \n",
    "\n",
    "Let us create different objects and do concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
